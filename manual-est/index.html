<!DOCTYPE HTML>

<!--Converted with LaTeX2HTML 2019.2 (Released June 5, 2019) -->
<HTML lang="EN">
<HEAD>
<TITLE>get_homologues-est manual</TITLE>
<META NAME="description" CONTENT="get_homologues-est manual">
<META NAME="keywords" CONTENT="manual-est">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="viewport" CONTENT="width=device-width, initial-scale=1.0">
<META NAME="Generator" CONTENT="LaTeX2HTML v2019.2">

<LINK REL="STYLESHEET" HREF="manual-est.css">

</HEAD>

<BODY >

<P>
<H1 class="CENTER">get_homologues-est manual</H1>
<P class="CENTER"><STRONG>Bruno Contreras-Moreira (1) and Pablo Vinuesa (2)</STRONG>
<BR><A ID="tex2html2"
  HREF="http://www.eead.csic.es">1. Estación Experimental de Aula Dei-CSIC</A>
<BR><A ID="tex2html3"
  HREF="http://www.ccg.unam.mx/~vinuesa">2. Centro de Ciencias Genómicas, Universidad Nacional Autónoma de México</A>
<BR>
</P>
<HR>

<P>
<BR>

<H2><A ID="SECTION00010000000000000000">
Contents</A>
</H2>
<!--Table of Contents-->

<UL CLASS="TofC">
<LI><A ID="tex2html122"
  HREF="manual-est.html#SECTION00020000000000000000">1 Description</A>
<LI><A ID="tex2html123"
  HREF="manual-est.html#SECTION00030000000000000000">2 Requirements and installation</A>
<UL>
<LI><A ID="tex2html124"
  HREF="manual-est.html#SECTION00031000000000000000">2.1 Perl modules</A>
<LI><A ID="tex2html125"
  HREF="manual-est.html#SECTION00032000000000000000">2.2 Required binaries</A>
<LI><A ID="tex2html126"
  HREF="manual-est.html#SECTION00033000000000000000">2.3 HPC configuration</A>
<LI><A ID="tex2html127"
  HREF="manual-est.html#SECTION00034000000000000000">2.4 Optional software dependencies</A>
</UL>
<BR>
<LI><A ID="tex2html128"
  HREF="manual-est.html#SECTION00040000000000000000">3 User manual</A>
<UL>
<LI><A ID="tex2html129"
  HREF="manual-est.html#SECTION00041000000000000000">3.1 Input data</A>
<LI><A ID="tex2html130"
  HREF="manual-est.html#SECTION00042000000000000000">3.2 Program options</A>
<LI><A ID="tex2html131"
  HREF="manual-est.html#SECTION00043000000000000000">3.3 Accompanying scripts</A>
</UL>
<BR>
<LI><A ID="tex2html132"
  HREF="manual-est.html#SECTION00050000000000000000">4 A few examples</A>
<UL>
<LI><A ID="tex2html133"
  HREF="manual-est.html#SECTION00051000000000000000">4.1 Extracting coding sequences (CDS) from transcripts</A>
<LI><A ID="tex2html134"
  HREF="manual-est.html#SECTION00052000000000000000">4.2 Clustering orthologous sequences from FASTA files, one per cultivar/ecotype/strain</A>
<LI><A ID="tex2html135"
  HREF="manual-est.html#SECTION00053000000000000000">4.3 Clustering sequences on a multicore Linux box, not a cluster</A>
<LI><A ID="tex2html136"
  HREF="manual-est.html#SECTION00054000000000000000">4.4 Producing a nucleotide-based pangenome matrix</A>
<LI><A ID="tex2html137"
  HREF="manual-est.html#SECTION00055000000000000000">4.5 Estimating protein domain enrichment of some sequence clusters</A>
<LI><A ID="tex2html138"
  HREF="manual-est.html#SECTION00056000000000000000">4.6 Making and annotating a non-redundant pangenome matrix</A>
<LI><A ID="tex2html139"
  HREF="manual-est.html#SECTION00057000000000000000">4.7 Annotating a sequence cluster</A>
<LI><A ID="tex2html140"
  HREF="manual-est.html#SECTION00058000000000000000">4.8 Output files explained</A>
</UL>
<BR>
<LI><A ID="tex2html141"
  HREF="manual-est.html#SECTION00060000000000000000">5 A step-by-step protocol with barley assembled transcripts</A>
<LI><A ID="tex2html142"
  HREF="manual-est.html#SECTION00070000000000000000">6 Frequently asked questions (FAQs)</A>
<LI><A ID="tex2html143"
  HREF="manual-est.html#SECTION00080000000000000000">7 Credits and references</A>
</UL>
<!--End of Table of Contents-->

<P>

<H1><A ID="SECTION00020000000000000000">
<SPAN CLASS="arabic">1</SPAN> Description</A>
</H1>

<P>
This document describes <SPAN  CLASS="textit">GET_HOMOLOGUES-EST</SPAN>, a fork of <SPAN  CLASS="textit">get_homologues</SPAN> for clustering homologous 
gene/transcript sequences of strains/populations of the same species. 
The source code and issue manager can be found at 
<A ID="tex2html5"
  HREF="https://github.com/eead-csic-compbio/get_homologues">https://github.com/eead-csic-compbio/get_homologues</A>.
This algorithm has been designed and tested with 
plant transcripts and CDS sequences, and uses BLASTN to compare DNA sequences. The main tasks for which this was conceived are:

<UL>
<LI>Finding and translating coding regions (CDSs) within raw transcripts.
</LI>
<LI>Clustering transcripts/CDS nucleotide sequences in homologous (possibly orthologous) groups, on the grounds of DNA sequence similarity.
</LI>
<LI>Definition of pan- and core-transcriptomes by calculation of overlapping sets of CDSs. 
</LI>
</UL>

<P>
The core algorithms of <SPAN  CLASS="textit">get_homologues-est</SPAN> have been adapted from <SPAN  CLASS="textit">get_homologues</SPAN>, and are therefore explained 
in <A ID="tex2html6"
  HREF="https://github.com/eead-csic-compbio/get_homologues/blob/master/manual_get_homologues.pdf">manual_get_homologues.pdf</A>. 
This document focuses mostly on EST-specific options.
<BR>
<P>
When obtaining twin DNA and peptide CDS files, the output of <SPAN  CLASS="textit">GET_HOMOLOGUES-EST</SPAN> can be used to drive phylogenomics 
and population genetics analyses with the kin pipeline <A ID="tex2html7"
  HREF="https://github.com/vinuesa/get_phylomarkers">GET_PHYLOMARKERS</A>.

<P>
This table lists features developed for <SPAN  CLASS="textit">get_homologues-est</SPAN> which were not available in the original <SPAN  CLASS="textit">get_homologues</SPAN> release, 
although most have been backported.

<P>
<BR><P></P>
<DIV class="CENTER"><A ID="631"></A>
<TABLE>
<CAPTION><STRONG>Table 1:</STRONG>
List of novel scripts/features in <SPAN  CLASS="textit">get_homologues-est</SPAN>.</CAPTION>
<TR><TD>
<DIV class="CENTER">
<TABLE class="PAD  BORDER" style="">
<TR><TD CLASS="LEFT">name</TD>
<TD CLASS="LEFT TOP"  WIDTH=360>description</TD>
</TR>
<TR><TD CLASS="LEFT">transcripts2cds.pl</TD>
<TD CLASS="LEFT TOP"  WIDTH=360>Script to extract coding sequences CDS from raw transcripts by combining Transdecoder and BLASTX.</TD>
</TR>
<TR><TD CLASS="LEFT">redundant isoform calling</TD>
<TD CLASS="LEFT TOP"  WIDTH=360><SPAN  CLASS="textit">get_homologues-est</SPAN> can handle redundant isoforms which otherwise will degrade clustering performance.</TD>
</TR>
<TR><TD CLASS="LEFT">ANI matrices</TD>
<TD CLASS="LEFT TOP"  WIDTH=360><SPAN  CLASS="textit">get_homologues-est</SPAN> can compute Average Nucleotide Identity (ANI) matrices which summarize the genetic distance among input genotypes.</TD>
</TR>
<TR><TD CLASS="LEFT">make_nr_pangenome_matrix.pl</TD>
<TD CLASS="LEFT TOP"  WIDTH=360>Produces a non-redundant pangenome matrix by comparing all nucleotide/peptide clusters to each other.</TD>
</TR>
<TR><TD CLASS="LEFT">pfam_enrich.pl</TD>
<TD CLASS="LEFT TOP"  WIDTH=360>Script to test whether a set of sequence clusters are enriched in some Pfam domains.</TD>
</TR>
<TR><TD CLASS="LEFT">annotate_cluster.pl</TD>
<TD CLASS="LEFT TOP"  WIDTH=360>Produces a multiple alignment view of the supporting local BLAST alignments of sequences in a cluster. 
It can also annotate Pfam domains and find private sequence variants private to an arbitrary group of sequences.</TD>
</TR>
</TABLE>
</DIV>

<A ID="tab:scripts"></A></TD></TR>
</TABLE>
</DIV><P></P>
<BR>

<P>

<H1><A ID="SECTION00030000000000000000"></A> <A ID="install"></A>
<BR>
<SPAN CLASS="arabic">2</SPAN> Requirements and installation
</H1>

<P>
<SPAN  CLASS="textit">get_homologues-est.pl</SPAN> is a Perl5 program bundled with a few binary files. 
The software has been tested on 64-bit Linux boxes, and on Intel MacOSX systems.
Therefore, a Perl5 interpreter is needed to run this software, which 
is usually installed by default on these operating systems. 

<P>
In order to install and test this software please follow these steps:

<OL>
<LI>Download a bundled release from <A ID="tex2html8"
  HREF="https://github.com/eead-csic-compbio/get_homologues/releases">https://github.com/eead-csic-compbio/get_homologues/releases</A>
</LI>
<LI>Unpack the software with: <code>$ tar xvfz get_homologues_X.Y.tgz</code> 
</LI>
<LI><code>$ cd get_homologues_X.Y</code>
</LI>
<LI><code>$ perl install.pl</code> 
<BR>
Please follow the indications in case some required part is missing. 

<P>
</LI>
<LI>Type <code>$ ./get_homologues-est.pl -v</code> which will tell exactly which features are available.
</LI>
<LI>Test the main Perl script, named <code>get_homologues-est.pl</code>, with the included sample input folder 

<P>
<code>sample_transcripts_fasta</code>
by means of the instruction:
<BR><code>$ ./get_homologues-est.pl -d sample_transcripts_fasta</code> . 
You should get an output similar to the contents of file <code>sample_transcripts_output.txt</code>. 

<P>
</LI>
<LI>Optionally modify your <code>$PATH</code> environment variable to include <SPAN  CLASS="textit">get_homologues-est.pl</SPAN>.
Please copy the following lines to the <code>.bash_profile</code> or 
<code>.bashrc</code> files, found in your home directory, replacing <code>[INSTALL_PATH]</code> by the full path of the installation folder:
<PRE>
export GETHOMS=[INSTALL_PATH]/get_homologues_X.Y
export PATH=${GETHOMS}/:${PATH}
</PRE>
This change will be effective in a new terminal or after running: <code>$ source ~/.bash_profile</code>
</LI>
</OL>

<P>
If you prefer a copy of the software that can be updated in the future you can get it from the <A ID="tex2html9"
  HREF="https://github.com/eead-csic-compbio/get_homologues">GitHub repository</A>
with:

<P>

<OL>
<LI><code>$ git clone https://github.com/eead-csic-compbio/get_homologues.git</code> 
</LI>
<LI><code>$ perl install.pl</code> 
<BR>
You would then be able to update it at anytime with:
</LI>
<LI><code>$ cd get_homologues</code>
</LI>
<LI><code>$ git pull</code> 
</LI>
</OL>

<P>
Finally, you can also install the software from <A ID="tex2html10"
  HREF="https://bioconda.github.io/">bioconda</A>
as follows:

<P>
<PRE>
$ conda activate bioconda
$ conda create -n get_homologues -c conda-forge -c bioconda get_homologues
$ conda activate get_homologues

# only if you want to install Pfam or SwissProt db
$ perl install.pl
</PRE>

<P>
See section <A HREF="#HPC">2.3</A> to learn how to configure the software to run on a HPC environment.

<P>
The rest of this section might be safely skipped if installation went fine, 
it was written to help solve installation problems.

<P>

<H2><A ID="SECTION00031000000000000000"></A> <A ID="perlmods"></A>
<BR>
<SPAN CLASS="arabic">2</SPAN>.<SPAN CLASS="arabic">1</SPAN> Perl modules
</H2>

<P>
A few Perl core modules are required by the <SPAN  CLASS="textit">get_homologues-est.pl</SPAN> script, which should be 
already installed on your system: Cwd, FindBin, File::Basename, File::Spec, File::Temp, FileHandle, List::Util, 
Getopt::Std, Benchmark and Storable.

<P>
In addition, the <SPAN  CLASS="textit">Bio::Seq</SPAN>, <SPAN  CLASS="textit">Bio::SeqIO</SPAN>, <SPAN  CLASS="textit">Bio::Graphics</SPAN> and <SPAN  CLASS="textit">Bio::SeqFeature::Generic</SPAN> 
modules from the <A ID="tex2html11"
  HREF="http://www.bioperl.org">Bioperl</A>
collection, 
and modules <A ID="tex2html12"
  HREF="http://search.cpan.org/~yanick/Parallel-ForkManager-1.19/lib/Parallel/ForkManager.pm">Parallel::ForkManager</A>,
<A ID="tex2html13"
  HREF="http://search.cpan.org/dist/URI/lib/URI/Escape.pm">URI::Escape</A>
are also required, and have been included in the <SPAN  CLASS="textit">get_homologues-est</SPAN> bundle for your convenience.

<P>
Should this version of BioPerl fail in your system (as diagnosed by <SPAN  CLASS="textit">install.pl</SPAN>) 
it might be necessary to install it from scratch. 
However, before trying to download it, you might want to check whether 
it is already living on your system, by typing on the terminal:
<BR><code>$ perl -MBio::Root::Version -e 'print $Bio::Root::Version::VERSION'</code>

<P>
If you get a message <code>Can't locate Bio/Root/Version...</code> then you need to actually install it, which 
can sometimes become troublesome due to failed dependencies. For this reason usually the easiest way of
installing it, provided that you have root privileges, 
it is to use the software manager of your Linux distribution (such as <SPAN  CLASS="textit">synaptic/apt-get</SPAN> 
in Ubuntu, <SPAN  CLASS="textit">yum</SPAN> in Fedora or <SPAN  CLASS="textit">YaST</SPAN> in openSUSE). If you prefer the terminal please use the 
<SPAN  CLASS="textit">cpan</SPAN> program with administrator privileges (<code>sudo</code> in Ubuntu): 
<BR><code>$ cpan -i C/CJ/CJFIELDS/BioPerl-1.6.1.tar.gz</code>

<P>
This form should be also valid:
<BR><code>$ perl -MCPAN -e 'install C/CJ/CJFIELDS/BioPerl-1.6.1.tar.gz'</code>
<BR>
Please check this <A ID="tex2html14"
  HREF="http://bioperl.open-bio.org/wiki/Installing_Bioperl_for_Unix">tutorial</A>
if you need further help.
<BR>
<P>

<H2><A ID="SECTION00032000000000000000"></A> <A ID="binaries"></A>
<BR>
<SPAN CLASS="arabic">2</SPAN>.<SPAN CLASS="arabic">2</SPAN> Required binaries
</H2>

<P>
In order to properly read (optionally) compressed input files, <SPAN  CLASS="textit">get_homologues-est</SPAN> requires <code>gunzip</code> and
<code>bunzip2</code>, which should be universally installed on most systems.

<P>
The Perl script <SPAN  CLASS="textit">install.pl</SPAN>, already mentioned in section <A HREF="#install">2</A>, checks whether the included 
precompiled binaries for <A ID="tex2html15"
  HREF="http://hmmer.janelia.org/">hmmer</A>, <A ID="tex2html16"
  HREF="http://www.micans.org/mcl">MCL</A>
and <A ID="tex2html17"
  HREF="ftp://ftp.ncbi.nlm.nih.gov/blast/executables/">BLAST</A>
are in place and ready to be used by <SPAN  CLASS="textit">get_homologues-est</SPAN>. 
This includes also <A ID="tex2html18"
  HREF="http://sourceforge.net/projects/cogtriangles/files/">COGtriangles</A>, which is used only by 
prokaryotic <SPAN  CLASS="textit">get_homologues</SPAN>. However, if any of these binaries fails to work in
your system, perhaps due a different architecture or due to missing libraries, it will be necessary to obtain 
an appropriate version for your system or to compile them with your own compiler.

<P>
In order to compile <SPAN  CLASS="textit">MCL</SPAN> the GNU <SPAN  CLASS="textit">gcc</SPAN> compiler is required, although it should most certainly already be 
installed on your system. If not, you might install it by any of the alternatives listed in section <A HREF="#perlmods">2.1</A>.
For instance, in Ubuntu this works well: <code>$ sudo apt-get install gcc</code> . The compilation steps are 
as follows:
<PRE>
$ cd bin/mcl-14-137;
$ ./configure`;
$ make
</PRE>

<P>
Regarding BLAST, <SPAN  CLASS="textit">get_homologues-est</SPAN> uses BLAST+ binaries, which
can be easily downloaded from the <A ID="tex2html19"
  HREF="ftp://ftp.ncbi.nlm.nih.gov/blast/executables/">NCBI FTP</A>
site.
The packed binaries are <SPAN  CLASS="textit">blastp</SPAN> and <SPAN  CLASS="textit">makeblastdb</SPAN> from version <SPAN  CLASS="textit">ncbi-blast-2.17.0+</SPAN>. If these do
not work in your machine or your prefer to use older BLAST versions, then it will be necessary to
edit file <SPAN  CLASS="textit">lib/phyTools.pm</SPAN>. First, environmental variable <code>$ENV{'BLAST_PATH'}</code> needs to be set to 
the right path in your system (inside subroutine <code>sub set_phyTools_env</code>).
<BR>
Variables <code>$ENV{'EXE_BLASTP'}</code> and <code>$ENV{'EXE_FORMATDB'}</code> also need to be changed to the appropriate
BLAST binaries, which are respectively <SPAN  CLASS="textit">blastall</SPAN> and <SPAN  CLASS="textit">formatdb</SPAN>.

<P>

<H2><A ID="SECTION00033000000000000000"></A> <A ID="HPC"></A>
<BR>
<SPAN CLASS="arabic">2</SPAN>.<SPAN CLASS="arabic">3</SPAN> HPC configuration
</H2>

<P>
It is possible and recommended to run <SPAN  CLASS="textit">get_homologues-est</SPAN> on a high-performance computing (HPC) cluster
invoking the program with option <code>-m cluster</code>.

<P>
For <A ID="tex2html20"
  HREF="http://gridscheduler.sourceforge.net/">gridengine</A>
environments (6.0u8, 6.2u4, 2011.11p1)
the script should work out of the box. For <A ID="tex2html21"
  HREF="https://en.wikipedia.org/wiki/Platform_LSF">LSF</A>
and
<A ID="tex2html22"
  HREF="https://slurm.schedmd.com/documentation.html">Slurm</A>
settings a configuration step is required.
In these cases you would need to create a file named <code>HPC.conf</code>
in the same location as <SPAN  CLASS="textit">get_homologues-est.pl</SPAN> tayloring your queue configuration and paths.
Alternatively it is possible to create a configuration file anywhere in your filesystem,
with <code>-m /path/custom/HPC.conf</code>, which is useful for <SPAN  CLASS="textbf">work for conda installs</SPAN>.
Check the sample configuration file at
<A ID="tex2html23"
  HREF="https://github.com/eead-csic-compbio/get_homologues/blob/master/sample.HPC.conf">sample.HPC.conf</A>.

<P>
If your computer farm is managed by <A ID="tex2html24"
  HREF="https://en.wikipedia.org/wiki/Platform_LSF">LSF</A>,
you should create a file named <code>HPC.conf</code> modifiying the provided template <code>sample.HPC.conf</code>
and adding a full path if necessary:

<P>
<PRE>
# cluster/farm configuration file, edit as needed (use spaces or tabs)
# comment lines start with #
# PATH might be empty or set to a path/ ending with '/', example:
#PATH	/lsf/10.1/linux3.10-glibc2.17-x86_64/bin/
TYPE	lsf
SUBEXE	bsub
CHKEXE	bjobs
DELEXE	bkill
ERROR	EXIT
</PRE>

<P>
If your farm is managed by <A ID="tex2html25"
  HREF="https://slurm.schedmd.com/documentation.html">Slurm</A>
instead,
the contents of the configuration file <code>HPC.conf</code> should be similar to this:

<P>
<PRE>
TYPE	slurm
SUBEXE	sbatch
CHKEXE	squeue
DELEXE	scancel
ERROR	F
</PRE>

<P>
For backwards compatibility, we provide here instructions on how to set up your own Grid Engine cluster.
<BR>
<PRE  CLASS="verbatim">### Debian 11 install (updated 08112021)
### (explained in Spanish at 
### https://bioinfoperl.blogspot.com/2021/10/howto-install-grid-engine-on-multi-core-box-debian.html.html)

   # this also creates user sgeadmin
   sudo apt install gridengine-master gridengine-qmon gridengine-exec

   # edit /etc/hosts 
   127.0.0.1 localhost.localdomain localhost
   127.0.1.1 master master
   121.xxx.yyy.zzz myhost
 
   # give yourself provileges
   sudo -u sgeadmin qconf -am myuser

   # and to a userlist
   qconf -au myuser users

   # Add a submission host
   qconf -as myhost

   # Add an execution host, you will be prompted for information about the execution host
   qconf -ae
 
   # Add a new host group
   qconf -ahgrp @allhosts

   # Add the exec host to the @allhosts list
   qconf -aattr hostgroup hostlist myhost @allhosts

   # Add and configure queue, set the slots matching your CPU/cores
   qconf -aq all.q

   # Add the host group to the queue
   qconf -aattr queue hostlist @allhosts  all.q

   # Make sure there is a slot allocated to the execd
   qconf -aattr queue slots "[myhost=1]" all.q


### Ubuntu install from SourceForge (updated 08112021)

# 1) go to  https://sourceforge.net/projects/gridengine/files/SGE/releases/8.1.9 , 
# create user 'sgeadmin' and download the latest binary packages
# (Debian-like here) matching your architecture (amd64 here):

wget -c https://sourceforge.net/projects/gridengine/files/SGE/releases/8.1.9/sge-common_8.1.9_all.deb/download
wget -c https://sourceforge.net/projects/gridengine/files/SGE/releases/8.1.9/sge_8.1.9_amd64.deb/download
wget -c https://sourceforge.net/projects/gridengine/files/SGE/releases/8.1.9/sge-dbg_8.1.9_amd64.deb/download

sudo useradd sgeadmin
sudo dpkg -i sge-common_8.1.9_all.deb 
sudo dpkg -i sge_8.1.9_amd64.deb
sudo dpkg -i sge-dbg_8.1.9_amd64.deb
sudo apt-get install -f

# 2) set hostname to anything but localhost by editing /etc/hosts so that 
# the first line is something like this (localhost or 127.0.x.x IPs not valid):
# 172.1.1.1   yourhost

# 3) install Grid Engine server with defaults except cluster name ('yourhost') 
# and admin user name ('sgeadmin'):
sudo su
cd /opt/sge/
chown -R sgeadmin sge
chgrp -R sgeadmin sge
./install_qmaster

# 4) install Grid Engine client with all defaults:
./install_execd
exit

# 5) check the path to your sge binaries, which can be 'lx-amd64'
ls /opt/sge/bin

# 6) Set relevant environment variables in /etc/bash.bashrc [can also be named /etc/basrhc] 
# or alternatively in ~/.bashrc for a given user
export SGE_ROOT=/opt/sge
export PATH=$PATH:"$SGE_ROOT/bin/lx-amd64" 

# 7) Optionally configure default all.q queue:
qconf -mq all.q

# 8) Add your host to list of admitted hosts:
qconf -as yourhost
</PRE>
<P>

<H2><A ID="SECTION00034000000000000000"></A> <A ID="dependencies"></A>
<BR>
<SPAN CLASS="arabic">2</SPAN>.<SPAN CLASS="arabic">4</SPAN> Optional software dependencies
</H2>

<P>
It is possible to invoke Pfam domain scanning from <SPAN  CLASS="textit">get_homologues-est</SPAN>. This option 
requires the bundled binary <SPAN  CLASS="textit">hmmscan</SPAN>, which is part of the <A ID="tex2html26"
  HREF="http://hmmer.janelia.org">HMMER3</A>
package,
whose path is set in file <SPAN  CLASS="textit">lib/phyTools.pm</SPAN> (variable <code>$ENV{'EXE_HMMPFAM'}</code>). 
Should this binary not work in your system, a fresh install might be the solution, say in <code>/your/path/hmmer-3.1b2/</code>.
In this case you'll have to edit file <SPAN  CLASS="textit">lib/phyTools.pm</SPAN> and modify the relevant:
<PRE>
if( ! defined($ENV{'EXE_HMMPFAM'}) )
{ 
	$ENV{'EXE_HMMPFAM'} = '/your/path/hmmer-3.1b2/src/hmmscan --noali --acc --cut_ga '; 
}
</PRE>
The Pfam HMM library is also required and the <SPAN  CLASS="textit">install.pl</SPAN> script should take care of it.
However, you can manually download it from the appropriate
<A ID="tex2html27"
  HREF="https://ftp.ebi.ac.uk/pub/databases/Pfam/current_release/Pfam-A.hmm.gz">Pfam FTP site</A>.
This file needs to be decompressed, either in the default <SPAN  CLASS="textit">db</SPAN> folder or in any other location, 
and then it should be formatted with the program <SPAN  CLASS="textit">hmmpress</SPAN>, which is also part of the 
<SPAN  CLASS="textit">HMMER3</SPAN> package. A valid command sequence could be:
<PRE>
$ cd db;
$ wget https://ftp.ebi.ac.uk/pub/databases/Pfam/current_release/Pfam-A.hmm.gz .;
$ gunzip Pfam-A.hmm.gz;
$ /your/path/hmmer-3.1b2/src/hmmpress Pfam-A.hmm
</PRE>
Finally, you'll need to edit file <SPAN  CLASS="textit">lib/phyTools.pm</SPAN> and modify the relevant line to:
<PRE>
if( ! defined($ENV{"PFAMDB"}) ){ $ENV{"PFAMDB"} = "db/Pfam-A.hmm"; }
</PRE>

<P>
In order to reduce the memory footprint of <SPAN  CLASS="textit">get_homologues-est</SPAN> it is possible to take advantage of the
<A ID="tex2html28"
  HREF="http://en.wikipedia.org/wiki/Berkeley_DB">Berkeley_DB</A>
database engine, which requires Perl core module
<A ID="tex2html29"
  HREF="http://search.cpan.org/perldoc?DB_File">DB_File</A>, which should be installed on all major Linux distributions.
If DB_File is not found within a conda environment you might have to run <code>conda deactivate</code> before.
Should manual installation be required, this can be done as follows:

<P>
<PRE>
$ yum -y install libdb-devel         # Redhat and derived distros

$ sudo apt-get -y install libdb-dev  # Ubuntu/Debian-based distros, and then cpan below

$ cpan -i DB_File                    # requires administrator privileges (sudo)
</PRE>

<P>
The accompanying script <SPAN  CLASS="textit">transcripts2cds.pl</SPAN> should work out of the box, but the more efficient
<SPAN  CLASS="textit">transcripts2cdsCPP.pl</SPAN> requires the installation of module 
<A ID="tex2html30"
  HREF="http://search.cpan.org/~davido/Inline-CPP-0.74/lib/Inline/CPP.pod">Inline::CPP</A>,
which in turn requires <A ID="tex2html31"
  HREF="http://search.cpan.org/~tinita/Inline-C-0.78/lib/Inline/C.pod">Inline::C</A>
and g++, the GNU C++ compiler.
The installation of these modules is known to be troublesome in some systems, but the standard way should work in most cases:

<P>
<PRE>
$ yum -y install gcc-c++ perl-Inline-C perl-Inline-CPP  # Redhat and derived distros

$ sudo apt-get -y install g++             # Ubuntu/Debian-based distros, and then cpan below

$ cpan -i Inline::C Inline::CPP           # will require administrator privileges (sudo)
</PRE>

<P>
This script may optionally use <A ID="tex2html32"
  HREF="https://github.com/bbuchfink/diamond">Diamond</A>
instead of BLASTX. 
The bundled linux binary should work out of the box; in case the macOS binary does not work in your system you might have to
re-compile it with:
<PRE>
cd bin/diamond-0.8.25/
build_simple.sh
cd ../../..
</PRE>

<P>
The accompanying scripts <SPAN  CLASS="textit">compare_clusters.pl</SPAN>, <SPAN  CLASS="textit">plot_pancore_matrix.pl</SPAN>, <SPAN  CLASS="textit">parse_pangenome_matrix.pl</SPAN>,
<BR>
<BR><SPAN  CLASS="textit">plot_matrix_heatmap.sh</SPAN>, <SPAN  CLASS="textit">hcluster_pangenome_matrix.sh</SPAN> require the installation of the statistical software 
<A ID="tex2html33"
  HREF="http://www.r-project.org">R</A>, 
which usually is listed by software managers in all major Linux distributions.
In some cases (some <A ID="tex2html34"
  HREF="http://cran.r-project.org/bin/linux/suse/README.html">SuSE versions</A>
and 
some <A ID="tex2html35"
  HREF="http://fedoraproject.org/wiki/EPEL/FAQ#How_can_I_install_the_packages_from_the_EPEL_software_repository.3F">Redhat-like distros</A>)
it will be necessary to add a repository to your package manager.
R can be installed  from the terminal:
<PRE>
$ sudo apt-get -y install r-base r-base-dev      # Ubuntu/Debian-based distros

$ yum -y install R                               # RedHat and derived distros

$ zypper --assume-yes R-patched R-patched-devel  # Suse
</PRE>

<P>
Please visit <A ID="tex2html36"
  HREF="http://cran.r-project.org/bin/macosx/">CRAN</A>
to download and install R on macOSX systems, which is straightforward.
<BR>
<BR>
<P>
In addition to R itself, <SPAN  CLASS="textit">plot_matrix_heatmap.sh</SPAN> and <SPAN  CLASS="textit">hcluster_pangenome_matrix.sh</SPAN> require some R packages to run, 
which can be easily installed from the R command line with: 
<PRE>
&gt; install.packages(c("ape", "gplots", "cluster", "dendextend, "factoextra"), dependencies=TRUE)
</PRE>

<P>
Finally, the script <SPAN  CLASS="textit">compare_clusters.pl</SPAN> might require the installation of program PARS from the 
<A ID="tex2html37"
  HREF="https://phylipweb.github.io/phylip/doc/pars.html">PHYLIP suite</A>, which should be already bundled 
with your copy of <SPAN  CLASS="textit">get_homologues</SPAN>.

<P>

<P>

<H1><A ID="SECTION00040000000000000000">
<SPAN CLASS="arabic">3</SPAN> User manual</A>
</H1>

<P>
This section describes the available options for the <SPAN  CLASS="textit">get_homologues-est</SPAN> software.

<P>

<H2><A ID="SECTION00041000000000000000"></A> <A ID="input"></A>
<BR>
<SPAN CLASS="arabic">3</SPAN>.<SPAN CLASS="arabic">1</SPAN> Input data
</H2>

<P>
This program takes input sequences in FASTA format, which might be GZIP- or BZIP2-compressed, contained in a 
directory or folder containing several files with extension '.fna', which can have twin <code>.faa</code> files with 
translated amino acid sequences for the corresponding CDSs (expected to be in same order). 
File names matching the tag 'flcdna' are handled as 
full-length transcripts, and this information will be used downstream in order to estimate coverage.
Global variable <code>$MINSEQLENGTH</code> controls the minimum length of sequences to be considered; the default value is 20.

<P>

<H2><A ID="SECTION00042000000000000000"></A> <A ID="options"></A>
<BR>
<SPAN CLASS="arabic">3</SPAN>.<SPAN CLASS="arabic">2</SPAN> Program options
</H2>

<P>
Typing <code>$ ./get_homologues-est.pl -h</code> on the terminal will show the basic options:
<SPAN CLASS="SPAN"></SPAN><PRE>
-v print version, credits and checks installation
-d directory with input FASTA files (.fna , optionally .faa),  (use of pre-clustered sequences
   1 per sample, or subdirectories (subdir.clusters/subdir_)    ignores -c)
   with pre-clustered sequences (.faa/.fna ). Files matching
   tag 'flcdna' are handled as full-length transcripts.
   Allows for files to be added later.
   Creates output folder named 'directory_est_homologues'

Optional parameters:
-o only run BLASTN/Pfam searches and exit                      (useful to pre-compute searches)
-i cluster redundant isoforms, including those that can be     (min overlap, default: -i 40,
   concatenated with no overhangs, and perform                  use -i 0 to disable)
   calculations with longest
-c report transcriptome composition analysis                   (follows order in -I file if enforced,
                                                                with -t N skips clusters occup&lt;N [OMCL],
                                                                ignores -r,-e)
-R set random seed for genome composition analysis             (optional, requires -c, example -R 1234)
-m runmode [local|cluster|dryrun|/path/custom/HPC.conf]        (def: local, path overrides ./HPC.conf)
-n nb of threads for BLASTN/HMMER/MCL in 'local' runmode       (default=2)
-I file with .fna files in -d to be included                   (takes all by default, requires -d)

Algorithms instead of default bidirectional best-hits (BDBH):
-M use orthoMCL algorithm (OMCL, PubMed=12952885)

Options that control sequence similarity searches:
-C min %coverage of shortest sequence in BLAST alignments      (range [1-100],default: -C 75)
-E max E-value                                                 (default: -E 1e-05 , max=0.01)
-D require equal Pfam domain composition                       (best with -m cluster or -n threads)
   when defining similarity-based orthology
-S min %sequence identity in BLAST query/subj pairs            (range [1-100],default: -S 95 [BDBH|OMCL])
-b compile core-transcriptome with minimum BLAST searches      (ignores -c [BDBH])

Options that control clustering:
-t report sequence clusters including at least t taxa          (default: t=numberOfTaxa,
                                                                t=0 reports all clusters [OMCL])
-L add redundant isoforms to clusters                          (optional, requires -i)
-r reference transcriptome .fna file                           (by default takes file with
                                                                least sequences; with BDBH sets
                                                                first taxa to start adding genes)
-e exclude clusters with inparalogues                          (by default inparalogues are
                                                                included)
-F orthoMCL inflation value                                    (range [1-5], default: -F 1.5 [OMCL])
-A calculate average identity of clustered sequences,          (optional, creates tab-separated matrix,
 uses blastn results                                            [OMCL])
-P calculate percentage of conserved sequences (POCS),         (optional, creates tab-separated matrix,
 uses blastn results, best with CDS                             [OMCL])
-z add soft-core to genome composition analysis                (optional, requires -c [OMCL])
</PRE><SPAN CLASS="SPAN"></SPAN>

<P>

<DIV class="CENTER"><A ID="fig:flow"></A><A ID="219"></A>
<TABLE>
<CAPTION class="BOTTOM"><STRONG>Figure 1:</STRONG>
Flowchart of get_homologues-est.</CAPTION>
<TR><TD>
<DIV class="CENTER">
<IMG STYLE=""
 SRC="./flow-est.png"
 ALT="Image flow-est">

</DIV></TD></TR>
</TABLE>
</DIV>

<P>
The only required option is <code>-d</code>, which indicates 
an input folder, as seen in section <A HREF="#input">3.1</A>. It is important to remark that in principle only files 
with extensions <code>.fna / .fa / .fasta</code> and optionally <code>.faa</code> are considered when parsing the <code>-d</code> directory. 
By using <code>.faa</code> input files protein sequences can be used to scan Pfam domains and included in output clusters.

<P>
The use of an input folder or directory (<code>-d</code>)
is recommended as it allows for new files to be added there in the future, reducing the computing required
for updated analyses. For instance, if a user does a first analysis with 5 input genomes today, it is possible
to check how the resulting clusters would change when adding an extra 10 genomes tomorrow, by copying these new 10 
<code>.fna</code> input files to the pre-existing <code>-d</code> folder, so that all previous BLASTN searches are re-used.

<P>
All remaining flags are options that can modify the default behavior of the program, which is to use the 
bidirectional best hit algorithm (BDBH) in order to compile clusters of potential orthologous DNA sequences,
taking the smallest genome as a reference. By default nucleotide sequences are used to guide the clustering, thus
relying on BLASTN searches.

<P>
Perhaps the most important optional parameter would be the choice of clustering algorithm (Table <A HREF="#tab:algs">2</A>):
<BR><P></P>
<DIV class="CENTER"><A ID="233"></A>
<TABLE>
<CAPTION><STRONG>Table 2:</STRONG>
List of available clustering algorithms. Note that the COG triangles algorithm is not supported.</CAPTION>
<TR><TD>
<DIV class="CENTER">
<TABLE class="PAD  BORDER" style="">
<TR><TD CLASS="LEFT">name</TD>
<TD CLASS="LEFT">option</TD>
<TD CLASS="LEFT TOP"  WIDTH=360>&nbsp;</TD>
</TR>
<TR><TD CLASS="LEFT">BDBH</TD>
<TD CLASS="LEFT">default</TD>
<TD CLASS="LEFT TOP"  WIDTH=360>Starting from a reference genome, keep adding genomes stepwise while storing the sequence clusters
that result of merging the latest bidirectional best hits.</TD>
</TR>
<TR><TD CLASS="LEFT">OMCL</TD>
<TD CLASS="LEFT"><code>-M</code></TD>
<TD CLASS="LEFT TOP"  WIDTH=360>OrthoMCL v1.4, uses the Markov Cluster Algorithm to group sequences,
with inflation (<code>-F</code>) controlling cluster granularity, as described in 
PubMed=<A ID="tex2html39"
  HREF="http://www.ncbi.nlm.nih.gov/sites/ppmc/articles/PMC403725/">12952885</A>.</TD>
</TR>
</TABLE>
</DIV>

<A ID="tab:algs"></A></TD></TR>
</TABLE>
</DIV><P></P>
<BR>

<P>
The remaining options are now reviewed:

<P>

<UL>
<LI>Apart from showing the credits, option <code>-v</code> can be helpful after installation, 
for it prints the enabled features of the program.

<P>
</LI>
<LI><code>-o</code> is ideally used to submit to a computer cluster the required BLAST (and Pfam) searches, preparing a job for posterior 
analysis on a single computer.

<P>
</LI>
<LI><code>-i</code> can be used to filter out short, redundant isoforms which overlap, with no overhangs, for a minimun length. 
By default this is set to <code>$MINREDOVERLAP=40</code> as in PubMed=<A ID="tex2html44"
  HREF="http://www.ncbi.nlm.nih.gov/pubmed/12651724">12651724</A>.
This EST-specific feature can be turned off by setting <code>-i 0</code>. Redundant isoforms will not be output unless <code>-L</code> is set. 

<P>

<DIV class="CENTER"><A ID="242"></A>
<TABLE>
<CAPTION class="BOTTOM"><STRONG>Figure 2:</STRONG>
Redundant isoforms (dashed) are optionally removed from an input sequence set if they overlap a longer 
sequence over a length <SPAN CLASS="MATH"><IMG
 WIDTH="36" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img1.png"
 ALT="$ \geq 40$"></SPAN> (A) or when they are completely matched (B). 
In either case a 100% sequence identity is required.
By calling option -L all redundant isoforms are included in the output.</CAPTION>
<TR><TD>
<DIV class="CENTER">
<IMG STYLE=""
 SRC="./isoforms.png"
 ALT="Image isoforms">

</DIV></TD></TR>
</TABLE>
</DIV>

<P>
</LI>
<LI><code>-c</code> is used to request a pan- and core-genome analysis of the input sequences, which will be output as tab-separated files. 
The number of samples for the genome composition analysis is set to 20 by default, but this can be edited at the header of 
<code>get_homologues-est.pl</code> (check the <code>$NOFSAMPLESREPORT</code> variable). As <SPAN  CLASS="textit">get_homologues-est</SPAN> is meant to be used primarily for 
the study of transcripts/CDSs of the same species, it uses appropriate thresholds to define new accessory genes 
(<code>$MIN_PERSEQID_HOM_EST=70</code>, <code>$MIN_COVERAGE_HOM_EST=50</code>), which mean that genes/transcripts added to the pool must be <SPAN CLASS="MATH"><IMG
 WIDTH="49" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img3.png"
 ALT="$ \geq 70\%$"></SPAN> 
identical in sequence to any previous sequence with cover <SPAN CLASS="MATH"><IMG
 WIDTH="49" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img4.png"
 ALT="$ \geq 50\%$"></SPAN> in order to be called homologous; otherwise they are handled as novel sequences. 
This low coverage is set in order to allow transcripts with retained/unprocessed introns to be matched.
The default identity value was chosen to match the fact that BLASTN::megablast hardly reports hits with lower identities in our tests 
with barley transcripts and <SPAN  CLASS="textit">A.thaliana</SPAN> CDS sequences.
Note that these default values are different to those set in <SPAN  CLASS="textit">get_homologues</SPAN> for peptide sequences. 
When combined with flag <code>-t</code> (see below), the composition analysis will disregard clusters reported in a selected number of strains.
This feature can be used to filter out singletons or artifacts which might arise from <SPAN  CLASS="textit">de novo</SPAN> assembled transcriptomes.

<P>

<DIV class="CENTER"><A ID="252"></A>
<TABLE>
<CAPTION class="BOTTOM"><STRONG>Figure 3:</STRONG>
Histograms of % identity reported by BLASTN among Arabidopsis thaliana CDS sequences (left) and Hordeum vulgare (right) transcripts. 
Note that the default BLASTN algorithm (megablast) hardly reports alignments with identities <SPAN CLASS="MATH"><IMG
 WIDTH="49" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img2.png"
 ALT="$ &lt;70\%$"></SPAN>. 
Plots were computed from 51,110,547 and 70,653,179 alignments, respectively.</CAPTION>
<TR><TD>
<DIV class="CENTER">
<IMG STYLE=""
 SRC="./histogram_BLASTN_id.png"
 ALT="Image histogram_BLASTN_id">

</DIV></TD></TR>
</TABLE>
</DIV>

<P>
</LI>
<LI><code>-R</code> takes a number that will be used to seed the random generator used with option <code>-c</code>. By using the
same seed in different <code>-c</code> runs the user ensures that genomes are sampled in the same order.

<P>
</LI>
<LI><code>-s</code> can be used to reduce the memory footprint, provided that the Perl module 
<A ID="tex2html45"
  HREF="http://search.cpan.org/perldoc?BerkeleyDB">BerkeleyDB</A>
is in place. 
This option usually makes <SPAN  CLASS="textit">get_homologues-est</SPAN> slower, but for very large datasets or in machines with little memory resources 
this might be the only way to complete a job.

<P>
</LI>
<LI><code>-m</code> allows the choice of runmode, which can be either <code>-m local</code> (the default),  
<code>-m cluster</code>, for computing farms configured as explained in section <A HREF="#dependencies">2.4</A>) and 
<code>-m dryrun</code>, which will allow you to run all required parallel jobs in batches manually.
Additionally <code>-m /path/custom/HPC.conf</code> can be used for cluster jobs that require a
custom HPC configuration file located elsewhere on the filesystem, useful for conda installs.
When combined with command-line tool <A HREF="#https:__www.gnu.org_software_parallel"><IMG  ALT="[*]" SRC="crossref.png"></A>parallel, 
the dryrun mode can be used to parallelize the clustering tasks (isoforms, orthologues, inparalogues, see <A HREF="#dryrun">4.3</A>).

<P>
</LI>
<LI><code>-n</code> sets the number of threads/CPUs to dedicate to each BLAST/HMMER/mcl job run locally, which by default is 2.

<P>
</LI>
<LI><code>-I list_file.txt</code> allows the user to restrict a <SPAN  CLASS="textit">get_homologues-est</SPAN> job to a subset of FASTA files included in the input <code>-d </code> folder. 
This flag can be used in conjunction with <code>-c</code> to control the order in which genomes are considered during pan- and core-transcriptome analyses.
Taking the <code>sample_RNAseq</code> folder, a valid <code>list_file.txt</code> could contain these lines:
<PRE>
Esterel.trinity.fna.bz2  
Franka.trinity.fna.bz2
</PRE>

<P>
</LI>
<LI>option <code>-C</code> sets the minimum percentage of coverage required to call two sequences best hits.
As EST/transcripts are frequently truncated, by default coverage is calculated with respect to the shortest sequence in the pair,
unless both of them come from a full-length collection (see <A HREF="#input">3.1</A>).

<P>

<DIV class="CENTER"><A ID="269"></A>
<TABLE>
<CAPTION class="BOTTOM"><STRONG>Figure 4:</STRONG>
Coverage illustrated with the alignment of sequence 'query' to two aligned fragments of sequence 'subject'.
Lq and Ls are the lengths of both sequences, and s1,e1,s2,e2 and Lq are alignment coordinates.</CAPTION>
<TR><TD>
<DIV class="CENTER">
<IMG STYLE=""
 SRC="./match_cover-est.png"
 ALT="Image match_cover-est">

</DIV></TD></TR>
</TABLE>
</DIV>

<P>
</LI>
<LI><code>-E</code> sets the maximum expectation value (E-value) for BLASTN alignments. This value is by default set to 1e-05. 

<P>
</LI>
<LI><code>-D</code> is an extra restriction for calling best hits, that should have identical Pfam domain compositions. Note that this
option requires scanning all input sequences for Pfam domains, and this task requires extra computing time, 
ideally on a computer cluster (<code>-m cluster</code>). 
While for BDBH domain filtering is done at the time bidirectional best hits are called, this processing step is performed only after the 
standard OMCL algorithms have completed, to preserve the algorithm features.

<P>
</LI>
<LI><code>-S</code> can be passed to require a minimum % sequence identity for two sequences to be called best hits. 
The default value is set to 95%, as in PubMed=<A ID="tex2html46"
  HREF="http://www.ncbi.nlm.nih.gov/pubmed/21572440">21572440</A>. 

<P>
</LI>
<LI><code>-b</code> reduces the number of pairwise BLAST searches performed while compiling core-genomes with algorithm BDBH,
reducing considerably memory and run-time requirements (for <SPAN CLASS="MATH"><IMG
 WIDTH="16" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img5.png"
 ALT="$ G$"></SPAN> genomes, 3G searches are launched instead of the default <SPAN CLASS="MATH"><IMG
 WIDTH="22" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img6.png"
 ALT="$ G^{2}$"></SPAN>).
It comes at the cost of being less exhaustive in finding inparalogues, but in our bacterial benchmarks this potential, undesired 
effect was negligible.

<P>
</LI>
<LI><code>-t</code> is used to control which sequence clusters should be reported. By default only clusters which include at least one sequence 
per genome are output. However, a value of <code>-t 2</code> would report all clusters containing sequences from at least 2 taxa. A especial
case is <code>-t 0</code>, which will report all clusters found, even those with sequences from a single genome. 

<P>
</LI>
<LI><code>-r</code> allows the choice of any input sequence set (of course included in <code>-d</code> folder) 
as the reference, instead of the default smaller one. If possible, resulting clusters are named using CDS/transcript names from 
this genome, which can be used to select well annotated species for this purpose. 

<P>
</LI>
<LI><code>-e</code> excludes clusters with inparalogues, defined as sequences with best hits in its own genome. 
This option might be helpful to rule out clusters including several sequences from the same species, which might be of 
interest for users employing these clusters for primer design, for instance.

<P>
</LI>
<LI><code>-F</code> is the inflation value that governs Markov Clustering in OMCL runs, as explained in 
PubMed=<A ID="tex2html47"
  HREF="http://www.ncbi.nlm.nih.gov/sites/ppmc/articles/PMC403725/">12952885</A>. As a rule of thumb,
low inflation values (<code>-F 1</code>)result in the inclusion of more sequences in fewer groups, whilst large values 
produce more, smaller clusters (<code>-F 4</code>).

<P>
</LI>
<LI><code>-A</code> tells the program to produce a tab-separated file with average % sequence identity values among pairs of genomes, 
computed from sequences in the final set of clusters (see also option <code>-t </code>). 
By default these identities are derived from BLASTN alignments, and hence correspond to nucleotide sequence identities, to
produce genomic average nucleotide sequence identities (ANI). 

<P>
</LI>
<LI><code>-P</code> tells the program to produce a tab-separated file with % of conserved sequence clusters shared by pairs of species. These values are computed the following expression adapted from
PubMed=<A ID="tex2html48"
  HREF="https://www.ncbi.nlm.nih.gov/pubmed/24706738">24706738</A>:
<BR>
<P>
<!-- MATH
 $POCS_{i,p} = 100 \frac{C_{i} + C_{j}}{total_{i} + total_{j}}$
 -->
<SPAN CLASS="MATH"><IMG STYLE="height: 3.93ex; vertical-align: -1.46ex; " SRC="img1.svg"
 ALT="$POCS_{i,p} = 100 \frac{C_{i} + C_{j}}{total_{i} + total_{j}}$"></SPAN>

<P>
where <SPAN CLASS="MATH"><IMG STYLE="height: 2.06ex; vertical-align: -0.46ex; " SRC="img2.svg"
 ALT="$C_{i}$"></SPAN> and <SPAN CLASS="MATH"><IMG STYLE="height: 2.38ex; vertical-align: -0.79ex; " SRC="img3.svg"
 ALT="$C_{j}$"></SPAN> represent the conserved number of nucleotide sequences in the two genomes being compared, respectively, and <SPAN CLASS="MATH"><IMG STYLE="height: 2.10ex; vertical-align: -0.46ex; " SRC="img4.svg"
 ALT="$total_{i}$"></SPAN> +and <SPAN CLASS="MATH"><IMG STYLE="height: 2.42ex; vertical-align: -0.79ex; " SRC="img5.svg"
 ALT="$total_{j}$"></SPAN> the total number of sequences in the two genomes being compared, respectively. These values are computed from sequences in the final set of clusters (see also option <code>-t </code>). 

<P>
</LI>
<LI><code>-z</code> can be called when performing a genome composition analysis with clustering algorithm OMCL.
In addition to the core- and pan-genome tab-separated files mentioned earlier (see option <code>-c</code>), this flag requests 
a soft-core report, considering all sequence clusters present in a fraction of genomes defined by global variable <code>$SOFTCOREFRACTION</code>,
with a default value of 0.95. This choice produces a composition report more robust to assembly or annotation errors than the core-genome.

<P>
</LI>
</UL>

<P>

<H2><A ID="SECTION00043000000000000000">
<SPAN CLASS="arabic">3</SPAN>.<SPAN CLASS="arabic">3</SPAN> Accompanying scripts</A>
</H2>

<P>
The following Perl and shell scripts are included in each release to assist in the interpretation of results generated
by <SPAN  CLASS="textit">get_homologues-est.pl</SPAN>. See examples of use in <SPAN  CLASS="textit">manual_get_homologues.pdf</SPAN>
<A ID="tex2html51"
  HREF="https://github.com/eead-csic-compbio/get_homologues/blob/master/manual_get_homologues.pdf">manual_get_homologues.pdf</A>:

<P>

<UL>
<LI><SPAN  CLASS="textit">compare_clusters.pl</SPAN> primarily calculates the intersection between cluster sets, 
which can be used to select clusters supported by different algorithms or settings.
This script can also produce pangenome matrices and Venn diagrams.

<P>
</LI>
<LI><SPAN  CLASS="textit">parse_pangenome_matrix.pl</SPAN> is a script that can be used to analyze pan-genome sets, in order to
find transcripts/genes present in a group A of strains which are absent in set B. This script can also be used
for calculating and plotting cloud, shell and core genome compartments. 

<P>
</LI>
<LI><SPAN  CLASS="textit">make_nr_pangenome_matrix.pl</SPAN> is provided to post-process pangenome matrices in case the user wishes 
to remove redundant clusters, using either nucleotide or protein sequence identity cut-offs.

<P>
</LI>
<LI><SPAN  CLASS="textit">plot_pancore_matrix.pl</SPAN>, a Perl script to plot pan/soft/core-genome sampling results and to fit regression 
curves with help from <A ID="tex2html52"
  HREF="http://www.r-project.org">R</A>
functions. 

<P>
</LI>
<LI><SPAN  CLASS="textit">check_BDBHs.pl</SPAN> is a script that can be used, after a previous <SPAN  CLASS="textit">get_homologues-est</SPAN> run, to find out the
bidirectional best hits of a sequence identifier chosen by the user. It can also retrieve the Pfam annotations of a sequence and its
reciprocal best hits. 

<P>
</LI>
<LI><SPAN  CLASS="textit">add_pancore_matrices.pl</SPAN> can be used to add pan/core-matrices produced by previous
<SPAN  CLASS="textit">get_homologues.est -c -R</SPAN> runs on the same set of genomes, with the aim of combining clusters.

<P>
</LI>
<LI><SPAN  CLASS="textit">annotate_cluster.pl</SPAN> produces a multiple alignment view of the supporting local BLAST alignments of sequences in a cluster. 
It can also annotate Pfam domains and find private sequence variants private to an arbitrary group of sequences.

<P>
</LI>
<LI><SPAN  CLASS="textit">plot_matrix_heatmap.sh</SPAN> calculates ordered heatmaps with attached row and column dendrograms from 
tab-separated numeric matrices, which can be presence/absence pangenomic matrices or similarity / identity matrices as those 
produced by <SPAN  CLASS="textit">get_homologues-est</SPAN> with flag <code>-A</code>. 

<P>
</LI>
<LI><SPAN  CLASS="textit">hcluster_pangenome_matrix.sh</SPAN> generates a distance matrix out of a tab-separated presence/absence pangenome matrix, 
which is then used to call R functions <code>hclust()</code> and <code>heatmap.2()</code> in order to produce a heatmap. 

<P>
</LI>
<LI><SPAN  CLASS="textit">pfam_enrich.pl</SPAN> calculates the enrichment of a set of sequence clusters in terms of Pfam domains,
by using <A ID="tex2html53"
  HREF="https://stat.ethz.ch/R-manual/R-patched/library/stats/html/fisher.test.html">Fisher's exact test</A>.

<P>
</LI>
</UL>

<P>
Apart from these, auxiliar <SPAN  CLASS="textit">transcripts2cds.pl</SPAN> script is bundled to assist in the
analysis of transcripts. In particular, this script can be used to annotate potential Open Reading Frames (ORFs) contained within raw transcripts, 
which might be truncated or contain introns. This script uses <A ID="tex2html54"
  HREF="https://transdecoder.github.io">TransDecoder</A>, BLASTX and SWISSPROT, which should 
be installed by running: <!-- MATH
 $./install.pl$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="77" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img7.png"
 ALT="$ ./install.pl$"></SPAN>

<P>
Ths program supports the following options:
<PRE> 
usage: ./transcripts2cds.pl [options] &lt;input FASTA file(s) with transcript nucleotide sequences&gt;

-h this message
-p check only 'plus' strand                                  (optional, default both strands)
-l min length for CDS                                        (optional, default=50 amino acid residues)
-g genetic code to use during translation                    (optional, default=1, example: -g 11)
-d run blastx against selected protein FASTA database file   (default=swissprot, example: -d db.faa)
-E max E-value during blastx search                          (default=1e-05)
-n number of threads for BLASTX jobs                         (default=2)
-X use diamond instead of blastx                             (optional, much faster for many sequences)

-G show available genetic codes and exit
</PRE> 

<P>
The main output of this script are two files, as shown in section <A HREF="#transcripts2cds">4.1</A>, which contain inferred nucleotide and peptide CDS sequences.
These FASTA files contain in each header the evidence supporting each called CDS, which can be <code>blastx</code>, <code>transdecoder</code> or 
a <code>combination of both</code>, giving precedence to <code>blastx</code> in case of conflict. 
Note that we have observed that the output of TransDecoder might change if a single sequence is analyzed alone, in contrast
to the analysis of a batch of sequences.
The next table shows the rules and evidence codes 
used by this script in order to call CDS sequences by merging BLASTX (1) and TransDecoder (2) predictions. The rules are mutually exclusive 
and are tested hierarchically from top to bottom. Sequences from 1 and 2 with less than 90 consecutive matches (30 amino acid residues) are considered 
to be non-overlapping (last rule). Note that the occurrence of mismatches are checked as a control:

<P>
<PRE> 
graphical summary         evidence             description

  1---------- 	           blastx	             no transdecoder	

  2----------	          transdecoder	         no blastx	

1----------          blastx.transdecoder       inferred CDS overlap with no 
     2-----------                              mismatches and are concatenated
     
     1----------     transdecoder.blastx       inferred CDS overlap with no 
2-----------                                   mismatches and are concatenated

1-----------------   blastx&lt;transdecoder       blastx CDS includes transdecoder CDS
   2-----------
   
     1----------     transdecoder&lt;blastx       transdecoder CDS includes blastx CDS
2------------------ 

1--------C--         blastx-mismatches         blastx CDS is returned as sequences  
     2---T------                               have mismatches

1-----               blastx-noover             blastx CDS is returned as transdecoder 
        2---                                   CDS does not overlap
</PRE> 

<P>
Our benchmarks suggest that 78 to 92% of deduced CDS sequences match the correct peptide sequences. :

<P>
<BR><P></P>
<DIV class="CENTER"><A ID="329"></A>
<TABLE>
<CAPTION><STRONG>Table 3:</STRONG>
Fraction of correct peptide sequences in deduced CDS obtained by combining BLASTX and TransDecoder.</CAPTION>
<TR><TD>
<DIV class="CENTER">
<TABLE class="PAD  BORDER" style="">
<TR><TD CLASS="LEFT">evidence</TD>
<TD CLASS="CENTER"><SPAN  CLASS="textit">Arabidopsis thaliana</SPAN> [Col-0]</TD>
<TD CLASS="RIGHT">n</TD>
<TD CLASS="CENTER"><SPAN  CLASS="textit">Hordeum vulgare</SPAN> [Haruna Nijo]</TD>
<TD CLASS="RIGHT">n</TD>
</TR>
<TR><TD CLASS="LEFT"><code>blastx</code></TD>
<TD CLASS="CENTER">0.787</TD>
<TD CLASS="RIGHT">960</TD>
<TD CLASS="CENTER">0.654</TD>
<TD CLASS="RIGHT">1,657</TD>
</TR>
<TR><TD CLASS="LEFT"><code>transdecoder</code></TD>
<TD CLASS="CENTER">0.914</TD>
<TD CLASS="RIGHT">8,194</TD>
<TD CLASS="CENTER">0.662</TD>
<TD CLASS="RIGHT">9,026</TD>
</TR>
<TR><TD CLASS="LEFT"><code>blastx.transdecoder</code></TD>
<TD CLASS="CENTER">0.930</TD>
<TD CLASS="RIGHT">4,678</TD>
<TD CLASS="CENTER">0.843</TD>
<TD CLASS="RIGHT">5,939</TD>
</TR>
<TR><TD CLASS="LEFT"><code>transdecoder.blastx</code></TD>
<TD CLASS="CENTER">0.959</TD>
<TD CLASS="RIGHT">15,700</TD>
<TD CLASS="CENTER">0.859</TD>
<TD CLASS="RIGHT">8,903</TD>
</TR>
<TR><TD CLASS="LEFT"><code>blastx&lt;transdecoder</code></TD>
<TD CLASS="CENTER">0.620</TD>
<TD CLASS="RIGHT">324</TD>
<TD CLASS="CENTER">0.674</TD>
<TD CLASS="RIGHT">218</TD>
</TR>
<TR><TD CLASS="LEFT"><code>transdecoder&lt;blastx</code></TD>
<TD CLASS="CENTER">0.966</TD>
<TD CLASS="RIGHT">6,581</TD>
<TD CLASS="CENTER">0.872</TD>
<TD CLASS="RIGHT">11,999</TD>
</TR>
<TR><TD CLASS="LEFT"><code>blastx-mismatches</code></TD>
<TD CLASS="CENTER">0</TD>
<TD CLASS="RIGHT">1</TD>
<TD CLASS="CENTER">&nbsp;</TD>
<TD CLASS="RIGHT">0</TD>
</TR>
<TR><TD CLASS="LEFT"><code>blastx-noover</code></TD>
<TD CLASS="CENTER">0.232</TD>
<TD CLASS="RIGHT">835</TD>
<TD CLASS="CENTER">0.426</TD>
<TD CLASS="RIGHT">2,211</TD>
</TR>
<TR><TD CLASS="LEFT">overall</TD>
<TD CLASS="CENTER">0.923</TD>
<TD CLASS="RIGHT">&nbsp;</TD>
<TD CLASS="CENTER">0.783</TD>
<TD CLASS="RIGHT">&nbsp;</TD>
</TR>
</TABLE>
</DIV>

<A ID="tab:CDSbench"></A></TD></TR>
</TABLE>
</DIV><P></P>
<BR>

<P>
The results obtained with DIAMOND instead of BLASTX are very similar:

<P>
<BR><P></P>
<DIV class="CENTER"><A ID="340"></A>
<TABLE>
<CAPTION><STRONG>Table 4:</STRONG>
Fraction of correct peptide sequences in deduced CDS obtained by combining DIAMOND and TransDecoder.</CAPTION>
<TR><TD>
<DIV class="CENTER">
<TABLE class="PAD  BORDER" style="">
<TR><TD CLASS="LEFT">evidence</TD>
<TD CLASS="CENTER"><SPAN  CLASS="textit">Arabidopsis thaliana</SPAN> [Col-0]</TD>
<TD CLASS="RIGHT">n</TD>
<TD CLASS="CENTER"><SPAN  CLASS="textit">Hordeum vulgare</SPAN> [Haruna Nijo]</TD>
<TD CLASS="RIGHT">n</TD>
</TR>
<TR><TD CLASS="LEFT"><code>blastx</code></TD>
<TD CLASS="CENTER">0.800</TD>
<TD CLASS="RIGHT">929</TD>
<TD CLASS="CENTER">0.655</TD>
<TD CLASS="RIGHT">1,598</TD>
</TR>
<TR><TD CLASS="LEFT"><code>transdecoder</code></TD>
<TD CLASS="CENTER">0.914</TD>
<TD CLASS="RIGHT">8,166</TD>
<TD CLASS="CENTER">0.663</TD>
<TD CLASS="RIGHT">8,980</TD>
</TR>
<TR><TD CLASS="LEFT"><code>blastx.transdecoder</code></TD>
<TD CLASS="CENTER">0.929</TD>
<TD CLASS="RIGHT">4,685</TD>
<TD CLASS="CENTER">0.844</TD>
<TD CLASS="RIGHT">5,951</TD>
</TR>
<TR><TD CLASS="LEFT"><code>transdecoder.blastx</code></TD>
<TD CLASS="CENTER">0.958</TD>
<TD CLASS="RIGHT">15,698</TD>
<TD CLASS="CENTER">0.859</TD>
<TD CLASS="RIGHT">8,890</TD>
</TR>
<TR><TD CLASS="LEFT"><code>blastx&lt;transdecoder</code></TD>
<TD CLASS="CENTER">0.615</TD>
<TD CLASS="RIGHT">325</TD>
<TD CLASS="CENTER">0.671</TD>
<TD CLASS="RIGHT">216</TD>
</TR>
<TR><TD CLASS="LEFT"><code>transdecoder&lt;blastx</code></TD>
<TD CLASS="CENTER">0.967</TD>
<TD CLASS="RIGHT">6,583</TD>
<TD CLASS="CENTER">0.872</TD>
<TD CLASS="RIGHT">11,999</TD>
</TR>
<TR><TD CLASS="LEFT"><code>blastx-mismatches</code></TD>
<TD CLASS="CENTER">&nbsp;</TD>
<TD CLASS="RIGHT">0</TD>
<TD CLASS="CENTER">&nbsp;</TD>
<TD CLASS="RIGHT">0</TD>
</TR>
<TR><TD CLASS="LEFT"><code>blastx-noover</code></TD>
<TD CLASS="CENTER">0.270</TD>
<TD CLASS="RIGHT">833</TD>
<TD CLASS="CENTER">0.452</TD>
<TD CLASS="RIGHT">2,190</TD>
</TR>
</TABLE>
</DIV>

<A ID="tab:CDSbenchX"></A></TD></TR>
</TABLE>
</DIV><P></P>
<BR>

<P>

<H1><A ID="SECTION00050000000000000000"></A> <A ID="default"></A>
<BR>
<SPAN CLASS="arabic">4</SPAN> A few examples
</H1>

<P>
This section presents typical ways of running <SPAN  CLASS="textit">get_homologues-est.pl</SPAN> 
and the accompanying scripts with provided sample input data. 
Please check file 
<A ID="tex2html55"
  HREF="https://github.com/eead-csic-compbio/get_homologues/blob/master/manual_get_homologues.pdf">manual_get_homologues.pdf</A>
for more examples, particularly for the auxiliary scripts,
which are not explained in this document.

<P>

<H2><A ID="SECTION00051000000000000000"></A> <A ID="transcripts2cds"></A>
<BR>
<SPAN CLASS="arabic">4</SPAN>.<SPAN CLASS="arabic">1</SPAN> Extracting coding sequences (CDS) from transcripts
</H2>

<P>
This example takes the provided sample file <code>sample_transcripts.fna</code> to demonstrate how to
annotate coding sequences contained in those sequences by calling <code>transcripts2cds.pl</code>.
Note that <code>transcripts2cdsCPP.pl</code> is significantly faster, but requires an optional Perl module (see <A HREF="#dependencies">2.4</A>).

<P>
This is an optional pre-processing step which you might not want to do, as the software should be able to properly handle any
nucleotides sequences suitable for BLASTN. However, coding sequences have the advantage that can be translated to amino acids and thus used
to scan Pfam domains further down in the analysis (see option <code>-D</code>).

<P>
A simple command would be, which will discard sequences less than 50b long, and will aligned them to SWISSPROT proteins in order to annotate
coding regions. In case of overlap, Transdecoder-defined and BLASTX-based coding regions are combined provided that a <code>$MINCONOVERLAP=90</code>
overlap, with no mismatches, is found; otherwise the latter are given higher priority:

<P>
<code>./transcripts2cdsCPP.pl -n 10 sample_transcripts.fna</code> 

<P>
The output should look like this (contained in file <code>sample_transcripts_output.txt</code>):
<PRE> 
# ./transcripts2cdsCPP.pl -p 0 -m  -d /path/get_homs-est/db/swissprot -E 1e-05 -l 50 -g 1 -n 10 -X 0
# input files(s):
# sample_transcripts.fna

## processing file sample_transcripts.fna ...
# running transdecoder...

# parsing transdecoder output (_sample_transcripts.fna_l50.transdecoder.cds.gz) ...
# running blastx...
# parsing blastx output (_sample_transcripts.fna_E1e-05.blastx.gz) ...
# calculating consensus sequences ...
# input transcripts = 9
# transcripts with ORFs = 7
# transcripts with no ORFs = 2
# output files: sample_transcripts.fna_l50_E1e-05.transcript.fna , 
# sample_transcripts.fna_l50_E1e-05.cds.fna , 
# sample_transcripts.fna_l50_E1e-05.cds.faa , 
# sample_transcripts.fna_l50_E1e-05.noORF.fna
</PRE>

<P>
The resulting CDS files can then be analyzed with <SPAN  CLASS="textit">get_homologues-est.pl</SPAN>.

<P>
Apart from the listed output files, which include translated protein sequences, temporary files are stored in the working directory,
which of course can be removed, but will be re-used if the same job is re-run later, such as
<BR><code>_sample_transcripts.fna_E1e-05.blastx.gz</code>, 
<BR><code>_sample_transcripts.fna_l50.transdecoder.cds.gz</code> or
<BR><code>_sample_transcripts.fna_l50.transdecoder.pep.gz</code>.
<BR>
<BR>
<P>
By default the script uses BLASTX (in combination with Transdecoder), 
which might take quite some time to process large numbers of sequences.
For this reason the DIAMOND algorithm is also available (upon calling option -X), 
which in our <A ID="tex2html56"
  HREF="http://bioinfoperl.blogspot.com.es/2016/11/diamond-as-replacement-of-blastx.html">benchmarks</A>
showed comparable performance and was several orders of magnitude faster when using multiple CPU cores.

<P>
CDS sequences can be deduced for a collection of transcriptomes and put in the same folder, 
so that they can all be analyzed together with <SPAN  CLASS="textit">get_homologues-est.pl</SPAN>. 
Such files support calling option <code>-D</code>, which will annotate Pfam domains contained in those sequences,
and can then also be used to calculate enrichment as explained in 
<A ID="tex2html57"
  HREF="https://github.com/eead-csic-compbio/get_homologues/blob/master/manual_get_homologues.pdf">manual_get_homologues.pdf</A>.

<P>

<H2><A ID="SECTION00052000000000000000"></A> <A ID="clustering"></A>
<BR>
<SPAN CLASS="arabic">4</SPAN>.<SPAN CLASS="arabic">2</SPAN> Clustering orthologous sequences from FASTA files, one per cultivar/ecotype/strain
</H2>

<P>
This example takes the sample input folder <code>sample_transcripts_fasta</code>,
which contains automatically assembled transcripts (<A ID="tex2html62"
  HREF="https://github.com/trinityrnaseq/trinityrnaseq/wiki">Trinity</A>) 
of three <SPAN  CLASS="textit">Hordeum vulgare</SPAN> strains (barley), plus a set of full-length cDNA collection of cultivar <SPAN  CLASS="textit">Haruna Nijo</SPAN>,
to show to produce clusters of transcripts.

<P>
The next command uses the OMCL algorithm to cluster sequences, produces a composition report, including the soft-core, and finally computes an Average Nucleotide Identity matrix on the produced clusters. 
Note that redundant isoforms are filtered, 
keeping only the longest one (you can turn this feature off with <code>-i 0</code>):
<BR>
<P>
<code>$ ./get_homologues-est.pl -d sample_transcripts_fasta -M -c -z -A </code> 

<P>
The output should look like this (contained in file <code>sample_transcripts_output.txt</code>):

<P>
<PRE> 
# results_directory=/path/sample_transcripts_fasta_est_homologues
# parameters: MAXEVALUEBLASTSEARCH=0.01 MAXPFAMSEQS=250 BATCHSIZE=100

# checking input files...
# Esterel.trinity.fna.bz2 5892  median length = 506
# Franka.trinity.fna.bz2 6036  median length = 523
# Hs_Turkey-19-24.trinity.fna.bz2 6204  median length = 476
# flcdnas_Hnijo.fna.gz 28620 [full length sequences] median length = 1504

# 4 genomes, 46752 sequences

# taxa considered = 4 sequences = 46752 residues = 63954041

# mask=Esterel_alltaxa_algOMCL_e0_ (_algOMCL)
[...]

# re-using previous isoform clusters
# 42 sequences
# 65 sequences
# 61 sequences
# 2379 sequences

# creating indexes, this might take some time (lines=2.08e+05) ...

# construct_taxa_indexes: number of taxa found = 4
# number of file addresses/BLAST queries = 4.4e+04

# genome composition report (samples=20,permutations=24,seed=0)
# genomic composition parameters: MIN_PERSEQID_HOM=70 MIN_COVERAGE_HOM=50 SOFTCOREFRACTION=0.95
[...]

# file=sample_transcripts_fasta_est_homologues/core_genome_algOMCL.tab
genomes	mean	stddev	|	samples
0	8559	6614	|	4665	4665	4665	...
1	1113	737	|	496	432	2007	...
2	255	101	|	84	308	347	...
3	66	0	|	66	66	66	...


# file=sample_transcripts_fasta_est_homologues/soft-core_genome_algOMCL.tab
genomes	mean	stddev	|	samples
0	8559	6614	|	4665	4665	4665	...
1	3491	2311	|	2428	2195	8108	...
2	2170	1017	|	765	3460	2145	...
3	645	101	|	816	592	553	...

# looking for valid sequence clusters (n_of_taxa=4)...

# number_of_clusters = 66
# cluster_list = sample_transcripts_fasta_est_homologues/Esterel_alltaxa_algOMCL_e0_.cluster_list
# cluster_directory = sample_transcripts_fasta_est_homologues/Esterel_alltaxa_algOMCL_e0_

# average_nucleotide_identity_matrix_file = # [...]/Esterel_alltaxa_algOMCL_e0_Avg_identity.tab
</PRE>

<P>
Notice that both core and soft-core sampling experiments are reported, considering sequences found in all strains and in 95% strains, respectively.
The produced Average Nucleotide Identity matrix looks like this:
<BR>
<DIV class="CENTER">
<TABLE class="PAD  BORDER" style="">
<TR><TD CLASS="LEFT">genomes</TD>
<TD CLASS="CENTER">Esterel</TD>
<TD CLASS="CENTER">Franka</TD>
<TD CLASS="CENTER">HsTurkey</TD>
<TD CLASS="CENTER">flcdnasHnijo</TD>
</TR>
<TR><TD CLASS="LEFT">Esterel</TD>
<TD CLASS="CENTER">100</TD>
<TD CLASS="CENTER">98.29</TD>
<TD CLASS="CENTER">98.04</TD>
<TD CLASS="CENTER">99.33</TD>
</TR>
<TR><TD CLASS="LEFT">Franka</TD>
<TD CLASS="CENTER">98.29</TD>
<TD CLASS="CENTER">100</TD>
<TD CLASS="CENTER">98.25</TD>
<TD CLASS="CENTER">98.90</TD>
</TR>
<TR><TD CLASS="LEFT">HsTurkey</TD>
<TD CLASS="CENTER">98.04</TD>
<TD CLASS="CENTER">98.25</TD>
<TD CLASS="CENTER">100</TD>
<TD CLASS="CENTER">98.41</TD>
</TR>
<TR><TD CLASS="LEFT">flcdnasHnijo</TD>
<TD CLASS="CENTER">98.33</TD>
<TD CLASS="CENTER">98.90</TD>
<TD CLASS="CENTER">98.41</TD>
<TD CLASS="CENTER">100</TD>
</TR>
</TABLE>
</DIV>
<A ID="tab:ANIsample"></A>
<BR>

<P>
Provided that optional R modules described in 
<A ID="tex2html63"
  HREF="https://github.com/eead-csic-compbio/get_homologues/blob/master/manual_get_homologues.pdf">manual_get_homologues.pdf</A>
are installed, this matrix can be plotted with the following command: 
<PRE>
./plot_matrix_heatmap.sh -i sample_[...]/Esterel_alltaxa_algOMCL_e0_Avg_identity.tab \
  -t "clusters=66" -k "Average Nucleotide Identity" -o pdf -m 28 -v 35 -H 9 -W 10
</PRE>

<P>

<DIV class="CENTER"><A ID="fig:ANImat"></A><A ID="382"></A>
<TABLE>
<CAPTION class="BOTTOM"><STRONG>Figure 5:</STRONG>
Heatmap of Average Nucleotide Identity.</CAPTION>
<TR><TD>
<DIV class="CENTER">
<IMG STYLE=""
 SRC="./Esterel_Avg_identity_heatmap.png"
 ALT="Image Esterel_Avg_identity_heatmap">

</DIV></TD></TR>
</TABLE>
</DIV>

<P>
If the previous command is changed by adding option <code>-t -2</code> only transcripts present in at least two strains will be considered,
which are output in folder: 
<BR><code>sample_transcripts_fasta_est_homologues/Esterel_2taxa_algOMCL_e0_</code>

<BR>
This second command produces a significantly different pan-genome composition matrix, which changes from:

<P>
<PRE>
# file=sample_transcripts_fasta_est_homologues/pan_genome_algOMCL.tab
genomes	mean	stddev	|	samples
0	8559	6614	|	4665	4665	4665	...
1	14830	6425	|	8937	9002	21292	...
2	21384	4866	|	13004	24283	23358	...
3	26380	468	|	27019	26209	25652	...
</PRE>

<P>
to

<P>
<PRE>
# file=sample_transcripts_fasta_est_homologues/pan_genome_2taxa_algOMCL.tab
genomes	mean	stddev	|	samples
0	2860	1172	|	2262	2262	2262	...
1	4270	490	|	4110	3828	4196	...
2	4953	424	|	5475	4767	4294	...
3	4954	424	|	5475	4768	4296	...
</PRE>

<P>
Both matrices can be plotted with script <SPAN  CLASS="textit">plot_pancore_matrix.pl</SPAN>, with a command such as: 
<BR><code> ./plot_pancore_matrix.pl -i sample_transcripts_fasta_est_homologues/pan_genome_algOMCL.tab -f pan</code>
<BR>
<P>

<DIV class="CENTER"><A ID="401"></A>
<TABLE>
<CAPTION class="BOTTOM"><STRONG>Figure 6:</STRONG>
Pan-transcriptome size estimates (-t 0, left) and (-t 2,  right) based on random samples of 4 transcriptome sets. 
As the left example illustrates, four strains are usually not enough to fit a Tettelin-like function.</CAPTION>
<TR><TD><TABLE   STYLE="width:50%;">
<TR><TD>
<DIV class="CENTER"><IMG STYLE=""
 SRC="./pan_genome_algOMCL.png"
 ALT="Image pan_genome_algOMCL">
</DIV></TD></TR>
</TABLE>
 
<TABLE   STYLE="width:50%;">
<TR><TD>
<DIV class="CENTER"><IMG STYLE=""
 SRC="./pan_genome_2taxa_algOMCL.png"
 ALT="Image pan_genome_2taxa_algOMCL">
</DIV></TD></TR>
</TABLE></TD></TR>
</TABLE>
</DIV>

<P>
The next figure shows a similar analysis but now using genomic data instead of transcript sets. The example shows pan-genome
size estimates of Whole Genome Sequence assemblies of 19  <i> Arabidopsis thaliana  </i> ecotypes, downloaded from
<A ID="tex2html64"
  HREF="http://mus.well.ox.ac.uk/19genomes/sequences/CDS">http://mus.well.ox.ac.uk/19genomes/sequences/CDS</A>
and described  
in PubMed=<A ID="tex2html65"
  HREF="http://www.ncbi.nlm.nih.gov/pubmed/21874022">21874022</A>.

<P>

<DIV class="CENTER"><A ID="fig:pangenomet"></A><A ID="635"></A>
<TABLE>
<CAPTION class="BOTTOM"><STRONG>Figure 7:</STRONG>

Core-genome, soft-core-genome and pan-genome CDS composition analysis of WGS assemblies of 19 A.thaliana ecotypes.
Note that the pan-genome simulation was done with all clusters (left) and with all clusters found in at least three genomes (right),
illustrating the effect of option -t 3, which might be useful to remove low confidence sequences.
Red numbers correspond to fitted values generated by <SPAN  CLASS="textit">plot_pancore_matrix.pl</SPAN>.
</CAPTION>
<TR><TD>
<DIV class="CENTER">
<IMG STYLE=""
 SRC="./pangenomet.png"
 ALT="Image pangenomet">

</DIV></TD></TR>
</TABLE>
</DIV>

<P>
Script <SPAN  CLASS="textit">plot_pancore_matrix.pl</SPAN> can also be called with flag -a:

<P>
<PRE>
./plot_pancore_matrix.pl -i sample_transcripts_fasta_est_homologues/pan_genome_algOMCL.tab \
  -f pan -a snapshots+
</PRE>

<P>
This will create and store a in folder <code>snapshots/</code> a series of GIF images that can be used to animate pan-genome simulations.
The next Figure show some of this snapshots:

<P>

<DIV class="CENTER"><A ID="fig:snapshot"></A><A ID="421"></A>
<TABLE>
<CAPTION class="BOTTOM"><STRONG>Figure 8:</STRONG>

Four snapshots of the pan-genome simulation carried out in the previous figure, generated by plot_pancore_matrix.pl.
</CAPTION>
<TR><TD>
<DIV class="CENTER">
<IMG STYLE=""
 SRC="./snapshot.png"
 ALT="Image snapshot">

</DIV></TD></TR>
</TABLE>
</DIV>

<P>

<H2><A ID="SECTION00053000000000000000"></A> <A ID="dryrun"></A>
<BR>
<SPAN CLASS="arabic">4</SPAN>.<SPAN CLASS="arabic">3</SPAN> Clustering sequences on a multicore Linux box, not a cluster
</H2>

<P>
This example takes the sample input folder <code>sample_transcripts_fasta</code>,
and demonstrates how you could run a large analysis on a multicore Linux box, not a computer cluster.
This example requires command-line tool <SPAN  CLASS="textit">parallel</SPAN>, 
which in Ubuntu can be installed with <code>sudo apt-get -y install</code>:

<P>
<PRE> 
# 1) run BLASTN (and HMMER) in batches
./get_homologues-est.pl -d sample_transcripts_fasta -o

# 2) run in -m dryrun mode
./get_homologues-est.pl -d sample_transcripts_fasta -m dryrun
# EXIT: check the list of pending commands at sample_transcripts_fasta_est_homologues/dryrun.txt
parallel &lt; sample_transcripts_fasta_est_homologues/dryrun.txt

# repeat 2) until completion
./get_homologues-est.pl -d sample_transcripts_fasta -m dryrun
# ...
</PRE>

<P>

<H2><A ID="SECTION00054000000000000000">
<SPAN CLASS="arabic">4</SPAN>.<SPAN CLASS="arabic">4</SPAN> Producing a nucleotide-based pangenome matrix</A>
</H2>

<P>
The clusters obtained in the previous section with option <code>-t 2</code> can be used to compile a pangenome matrix
without singletons with this command:
<BR><code>./compare_clusters.pl -d sample_[...]/Esterel_2taxa_algOMCL_e0_ -o outdir -n -m</code>

<BR><PRE>
# number of input cluster directories = 1

# parsing clusters in sample_transcripts_fasta_est_homologues/Esterel_2taxa_algOMCL_e0_ ...
# cluster_list in place, will parse it (sample_[...]/Esterel_2taxa_algOMCL_e0_.cluster_list)
# number of clusters = 5241

# intersection output directory: outdir

# intersection size = 5241 clusters

# intersection list = outdir/intersection_t0.cluster_list

# pangenome_file = outdir/pangenome_matrix_t0.tab (and transposed)
# pangenome_genes = outdir/pangenome_matrix_genes_t0.tab (and transposed)
# pangenome_phylip file = outdir/pangenome_matrix_t0.phylip 
# pangenome_FASTA file = outdir/pangenome_matrix_t0.fasta
# pangenome CSV file (Scoary) = outdir/pangenome_matrix_t0.tr.csv
</PRE>

<P>
The following, taken from the 
<A ID="tex2html67"
  HREF="http://eead-csic-compbio.github.io/get_homologues/plant_pangenome/protocol.html#pangenome-analyses">tutorial</A>,
explains the different versions of the same pangenome/pangene matrix:

<P>
<code>pangenome_matrix_t0.tab</code> is a numeric matrix with tab-separated (TSV) columns, with taxa/genomes as rows and sequence clusters as columns, in which cells with natural numbers indicate whether a given taxa contains 1+ sequences from a given cluster. It can be read and edited with any text editor or spreadsheet software, and is also produced in transposed form for convenience. For example, users might want to sort the clusters by position on a reference genome and use these matrices to visualize results.

<P>
<code>pangenome_matrix_genes_t0.tab</code> is similar to the previous one, but contains the actual sequence names in each cluster instead.

<P>
<code>pangenome_matrix_t0.phylip</code> is a reduced binary matrix in a format suitable for PHYLIP discrete character analysis software.

<P>
<code>pangenome_matrix_t0.fasta</code> is a reduced binary matrix in FASTA format suitable for binary character analysis software such as 
<A ID="tex2html68"
  HREF="http://www.iqtree.org">IQ-TREE</A>, which can compute bootstrap and aLRT support.

<P>
<code>pangenome_matrix_t0.tr.csv</code> is a transposed, reduced binary matrix in CSV format suitable for pangenome-wide association analysis with software <A ID="tex2html69"
  HREF="https://github.com/AdmiralenOla/Scoary">Scoary</A>.

<P>
If the optional R modules described in 
<A ID="tex2html70"
  HREF="https://github.com/eead-csic-compbio/get_homologues/blob/master/manual_get_homologues.pdf">manual_get_homologues.pdf</A>
are installed, such a pangenome matrix can be used to hierarchically cluster strains with this command:
<BR><code>./hcluster_pangenome_matrix.sh -i outdir/pangenome_matrix_t0.tab</code>

<P>

<DIV class="CENTER"><A ID="fig:hclustpange"></A><A ID="444"></A>
<TABLE>
<CAPTION class="BOTTOM"><STRONG>Figure 9:</STRONG>
Hierarchical grouping of strains based on pangenome matrix.</CAPTION>
<TR><TD>
<DIV class="CENTER">
<IMG STYLE=""
 SRC="./pangenome_matrix_t0_heatmap-est.png"
 ALT="Image pangenome_matrix_t0_heatmap-est">

</DIV></TD></TR>
</TABLE>
</DIV>

<P>

<H2><A ID="SECTION00055000000000000000">
<SPAN CLASS="arabic">4</SPAN>.<SPAN CLASS="arabic">5</SPAN> Estimating protein domain enrichment of some sequence clusters</A>
</H2>

<P>
This example uses data from the barley benchmark, the <code>test_barley/</code> folder,
which contains instructions to download sequences from: 
<A ID="tex2html71"
  HREF="http://floresta.eead.csic.es/plant-pan-genomes">http://floresta.eead.csic.es/plant-pan-genomes</A>
<P>
After completing the downloads, the folder will contain FASTA files with nucleotide sequences of 14 de-novo assembled transcriptomes 
and transcripts/cDNA sequences annotated in reference accessions Morex and Haruna Nijo. CDS can be extracted as explained 
in Section <A HREF="#protocol">5</A> and then Pfam domains can be annotated as follows:

<P>
<code>$ ./get_homologues-est.pl -d cds -D -o -m cluster </code> 

<P>

<BR>
These annotations will serve to calculate background domain frequencies.

<P>
Once this is completed, we can compute "control" clusters with this command:
<BR><code>$ ./get_homologues-est.pl -d cds -M -m cluster </code> 

<P>

<BR>
which we will then place in a folder called <code>clusters_cds</code>:
<BR><PRE>
compare_clusters.pl -d cds_est_homologues/Alexis_0taxa_algOMCL_e0_ \
  -o clusters_cds -m -n+
</PRE>

<P>
In order to call accessory sequences with more confidence we will use only non-cloud clusters (<!-- MATH
 $occupancy > 2$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="101" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img8.png"
 ALT="$ occupancy &gt; 2$"></SPAN>), which we do with this command:
<BR><code>$ ./get_homologues-est.pl -d cds -M -t 3 -m cluster </code>

<P>

<BR>
The output should include the next lines:
<PRE> 
# number_of_clusters = 34248
# cluster_list = cds_est_homologues/Alexis_3taxa_algOMCL_e0_.cluster_list
# cluster_directory = cds_est_homologues/Alexis_3taxa_algOMCL_e0_
</PRE>

<P>
We should be now in position to compile the pan-genome matrix corresponding to these clusters:
<PRE>
./compare_clusters.pl -d cds_est_homologues/Alexis_3taxa_algOMCL_e0_ \
  -o clusters_cds_t3 -m -n
</PRE>

<P>

<BR>
which should produce:
<PRE> 
# number of clusters = 34248

# intersection output directory: clusters_cds_t3
# intersection size = 34248 clusters

# intersection list = clusters_cds_t3/intersection_t0.cluster_list

# pangenome_file = clusters_cds_t3/pangenome_matrix_t0.tab
# pangenome_phylip file = clusters_cds_t3/pangenome_matrix_t0.phylip
</PRE>

<P>
We should now interrogate the pan-genome matrix, for instance looking for clusters found in one genotype (A) but not in others (B):

<P>
<PRE> 
./parse_pangenome_matrix.pl -m clusters_cds_t3/pangenome_matrix_t0.tab \
  -A cds/SBCC073.list -B cds/ref.list -g
</PRE> 

<P>
You should obtain a list of 4348 accessory clusters:

<P>
<PRE> 
# matrix contains 34248 clusters and 16 taxa

# taxa included in group A = 1

# taxa included in group B = 2

# finding genes present in A which are absent in B ...
# file with genes present in set A and absent in B (4348): 
  clusters_cds_t3/pangenome_matrix_t0__pangenes_list.txt
</PRE> 

<P>
Finally, we will now estimate whether these clusters are enriched in any Pfam domain, producing also a single FASTA 
file with the tested sequences:

<P>
<PRE> 
./pfam_enrich.pl -d cds_est_homologues -c clusters_cds -n -t greater \
  -x clusters_cds_t3/pangenome_matrix_t0__pangenes_list.txt -e -p 0.05 \
  -r SBCC073 -f SBCC073_accessory.fna
</PRE>

<P>
The output should be:
<PRE>
# 39400 sequences extracted from 113222 clusters

# total experiment sequence ids = 4818
# total control    sequence ids = 39400

# parse_Pfam_freqs: set1 = 562 Pfams set2 = 3718 Pfams


# created FASTA file: SBCC073_accessory.fna

# sequences=4818 mean length=353.8 , seqs/cluster=1.11

# fisher exact test type: 'greater'
# multi-testing p-value adjustment: fdr
# adjusted p-value threshold: 1

# total annotated domains: experiment=1243 control=19192

#PfamID counts(exp) counts(ctr) freq(exp) freq(ctr) p-value p-value(adj)  description
PF00009 0 20  0.000e+00 1.042e-03 1.000e+00 1.000e+00 Elongation factor Tu GTP binding domain
PF00010 0 32  0.000e+00 1.667e-03 1.000e+00 1.000e+00 Helix-loop-helix DNA-binding domain
...
PF00665 13  31  1.046e-02 1.615e-03 1.418e-06 1.318e-03 Integrase core domain
PF07727 28  61  2.253e-02 3.178e-03 3.033e-13 1.128e-09 Reverse transcriptase (RNA-dep DNA pol)
PF00931 44  201 3.540e-02 1.047e-02 1.750e-10 3.253e-07 NB-ARC domain
PF13976 14  19  1.126e-02 9.900e-04 2.744e-09 3.401e-06 GAG-pre-integrase domain
</PRE>

<P>

<H2><A ID="SECTION00056000000000000000">
<SPAN CLASS="arabic">4</SPAN>.<SPAN CLASS="arabic">6</SPAN> Making and annotating a non-redundant pangenome matrix</A>
</H2>

<P>
The script <code>make_nr_pangenome_matrix.pl</code> produces a non-redundant pangenome matrix by 
comparing all clusters to each other, taking the median sequence in each cluster. 
By default nucleotide sequences are compared, but if the original input of 
<SPAN  CLASS="textit">get_homologues-est</SPAN> comprised both DNA and protein sequences, the user can also choose peptide
sequences to compute redundancy, which probably make more sense in terms of protein function.
On the contrary, it would seem more appropriate to use DNA sequences to measure diversity.

<P>
In this example a DNA-based non-redundant pangenome matrix is computed with BLASTN assuming 
that sequences might be truncated (option <code>-e</code>) and using 10 processor cores and a coverage cutoff of 50%:
<BR><code>./make_nr_pangenome_matrix.pl -m outdir/pangenome_matrix_t0.tab -n 10 -e -C 50</code>

<P>
<PRE>
# input matrix contains 5241 clusters and 4 taxa

# filtering clusters ...
# 5241 clusters with taxa &gt;= 1 and sequence length &gt;= 0

# sorting clusters and extracting median sequence ...

# running makeblastdb with outdir/pangenome_matrix_t0_nr_t1_l0_e1_C50_S90.fna

# parsing blast result! (outdir/pangenome_matrix_t0_nr_t1_l0_e1_C50_S90.blast , 0.37MB)
# parsing file finished

# 5172 non-redundant clusters
# created: outdir/pangenome_matrix_t0_nr_t1_l0_e1_C50_S90.fna

# printing nr pangenome matrix ...
# created: outdir/pangenome_matrix_t0_nr_t1_l0_e1_C50_S90.tab
</PRE>

<P>
Note that the previous command can be modified to match external reference sequences, 
for instance from <A ID="tex2html72"
  HREF="http://www.ebi.ac.uk/uniprot">Swissprot</A>,
or pre-computed clusters, such as groups of orthologous sequences, 
so that the resulting matrix contains cross-references to those external clusters, and their annotations.
In either case, both input clusters and reference sequences must be of the same type: either nucleotides or peptides.

<P>
The next example shows how a set of clusters produced by <SPAN  CLASS="textit">get_homologues-est</SPAN> can be matched to some nucleotide 
reference sequences, in this case annotated rice cDNAs:

<P>
<code>./make_nr_pangenome_matrix.pl -m outdir/pangenome_matrix_t0.tab -n 10 -e -C 50 -f oryza.fna</code>

<P>
This is the produced output:
<PRE>
# input matrix contains 5241 clusters and 4 taxa

# filtering clusters ...
# 5241 clusters with taxa &gt;= 1 and sequence length &gt;= 0

# sorting clusters and extracting median sequence ...
# re-using previous BLAST output outdir/pangenome_matrix_t0_nr_t1_l0_e1_C50_S90.blast

# parsing blast result! (outdir/pangenome_matrix_t0_nr_t1_l0_e1_C50_S90.blast , 0.34MB)
# parsing file finished

# 5172 non-redundant clusters
# created: outdir/pangenome_matrix_t0_nr_t1_l0_e1_C50_S90.fna

# 66339 reference sequences parsed in oryza.fna

# parsing blast result! (outdir/pangenome_matrix_t0_nr_t1_l0_e1_C50_S90_ref.blast , 0.37MB)
# parsing file finished

# matching nr clusters to reference (%alignment coverage cutoff=50) ...

# printing nr pangenome matrix ...
# created: outdir/pangenome_matrix_t0_nr_t1_l0_e1_C50_S90_ref_c50_s50.tab

# NOTE: matrix can be transposed for your convenience with:

  perl -F'\t' -ane '$r++;for(1 .. @F){$m[$r][$_]=$F[$_-1]}; \
    $mx=@F;END{for(1 .. $mx){for $t(1 .. $r){print"$m[$t][$_]\t"}print"\n"}}' \
    outdir/pangenome_matrix_t0_nr_t1_l0_e1_C50_S90_ref_c50_s50.tab
</PRE>

<P>
The suggested perl command can be invoked to tranpose the matrix, which now contains rows such as these:
<PRE>
non-redundant	Franka.bz2.nucl	Esterel.bz2.nucl	flcdnas_Hnijo.gz.nucl	...	redundant	reference	
1_TR2804-c0_g1_i1.fna	1	1	0	0	NA	LOC_Os09g07300.1 cDNA|BIG, putative, expressed	
2_TR1554-c0_g1_i1.fna	0	2	1	0	NA	LOC_Os03g53280.1 cDNA|WD domain containing protein	
6_TR3918-c0_g1_i1.fna	0	1	1	0	NA	NA	
...
</PRE>

<P>
Pangenome matrices with more than 4 taxa can be plotted with help from script <SPAN  CLASS="textit">parse_pangenome_matrix.pl</SPAN>,
as explained in <A ID="tex2html73"
  HREF="https://github.com/eead-csic-compbio/get_homologues/blob/master/manual_get_homologues.pdf">manual_get_homologues.pdf</A>. 

<P>

<H2><A ID="SECTION00057000000000000000">
<SPAN CLASS="arabic">4</SPAN>.<SPAN CLASS="arabic">7</SPAN> Annotating a sequence cluster</A>
</H2>

<P>
After analyzing pan-genome or pan-transcriptome clusters it might be interesting to find out what kind of transcripts or proteins they encode,
or we might just want to double-check the BLAST matches that support a produced cluster. 
The script <SPAN  CLASS="textit">annotate_cluster.pl</SPAN> does just that, and can be used with both nucleotide and peptide clusters.
Note that in this first example it prints also the PFam domains <code>(-D)</code> annotated in those sequences:

<P>
<code>./annotate_cluster.pl -f outdir/1004_TR425-c0_g2_i1.fna -o 1004_TR425-c0_g2_i1.aln.fna -D</code>
<BR>
<P>
And will produce this output:

<P>
<PRE>
# DEFBLASTNTASK=megablast DEFEVALUE=10
# MINBLUNTBLOCK=100 MAXSEQNAMELEN=60
# MAXMISMCOLLAP=0 MAXGAPSCOLLAP=2

# ./annotate_cluster.pl -f outdir/1004_TR425-c0_g2_i1.fna -r  \
#     -o 1004_TR425-c0_g2_i1.aln.fna -P 1 -b 0 -D 1 -c 0 -A  -B 

# total   sequences: 3 taxa: 2

# Pfam domains: PF10602,PF01399,
# Pfam annotation: 26S proteasome subunit RPN7;PCI domain;
# aligned sequences: 3 width:   1595

# alignment sites: SNP=3 parsimony-informative=0 (outdir/1004_TR425-c0_g2_i1.fna)

# taxa included in alignment: 2

# alignment file: 1004_TR425-c0_g2_i1.aln.fna
</PRE>

<P>
If option <code>-b</code> is enforced a blunt-end alignment is produced, which might be useful for further analyses.
In either case, the produced FASTA alignment file will contain Pfam domains in each header,
in addition to the relevant BLAST scores:

<P>
<PRE>
&gt;TR425|c0_g2_i1_[Esterel.trinity.fna.bz2] bits E-value N qy ht 1:1595 Pfam:..
CCTGCTGGTGCATTTTTTTACAAACAGTTGGCACAGAGTATTTGTTGCTAATTGTGTTCGTTTTCTTGAA...
</PRE>

<P>

<DIV class="CENTER"><A ID="fig:annotcluster"></A><A ID="636"></A>
<TABLE>
<CAPTION class="BOTTOM"><STRONG>Figure 10:</STRONG>
Fragment of alignment produced by annotate_cluster.pl, 
rendered with <A ID="tex2html74"
  HREF="http://www.mbio.ncsu.edu/bioedit/bioedit.html">BioEdit</A>.</CAPTION>
<TR><TD>
<DIV class="CENTER">
<IMG STYLE=""
 SRC="./annotcluster.png"
 ALT="Image annotcluster">

</DIV></TD></TR>
</TABLE>
</DIV>

<P>
Optionally <code>-c </code> can also be invoked to collapse aligned sequences from the same species or taxon.
This might be useful when working with clusters of transcript isoforms, which are often redundant and
broken in possibly overlapping fragments. Taking the same example cluster, we could try to collapse 
isoforms with overlaps <SPAN CLASS="MATH"><IMG
 WIDTH="36" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img9.png"
 ALT="$ \geq 30$"></SPAN> residues like this:

<P>
<code>./annotate_cluster.pl -f outdir/1004_TR425-c0_g2_i1.fna -o 1004_TR425-c0_g2_i1.aln.fna -D -c 30</code>
<BR>
<P>
This script does not tolerate mismatches between sequences to be collapsed; however,  
that behaviour can be relaxed by editing the value of variable <code>$MAXMISMCOLLAP=0</code> at the top of the 
script. 
Instead, as BLASTN-placed gaps in identical sequences can often move, by default two such gaps are accepted 
(see variable <code>MAXGAPSCOLLAP=2</code>).

<P>
By default, the script <code>annotate_cluster.pl</code> looks for the longest sequences and aligns all other cluster
sequences to it with BLASTN (megablast). The user can also pass an external, reference sequence to guide cluster
alignment (see option <code>-r</code>). However, in either case, clusters of transcripts often contain a fraction 
of BLASTN hits that do not match the longest/reference sequence; instead, they align towards the 5' or 3' of 
other sequences of the clusters and are thus not included in the produced multiple sequence alignment (MSA):

<P>
<PRE>
 -----------------            &lt;= longest/reference sequence
              -------------
    -------------
 -----------
   ------------
                      ....    &lt;= sequences not included in MSA
                       ..
</PRE>

<P>
We called these pseudo-multiple alignments as they are computed from pairwise alignments of the longest/reference (query) 
to all other cluster sequences. The resulting alignment is produced by <A ID="tex2html77"
  HREF="https://github.com/desmid/mview">MVIEW</A>, 
which does not record deletions in the query sequence. This means that an alignment like this:

<P>
<PRE>
 ------  -----------            &lt;= longest/reference sequence
    ---..----------             &lt;= .. fragment not included in MSA
 ------  -----
   ----  --------
</PRE>

<P>
will in fact be saved as:

<P>
<PRE>
-----------------            
   -------------             
-----------
  ------------
</PRE>

<P>
In case you want to compute full multiple sequence alignments, including all indels, please use option <code>-u</code>).
This way the script will produce unaligned complete sequences, flipped if required,
so that external software (clustal-omega, muscle, MAFFT, etc) can be used to align them.

<P>

<H2><A ID="SECTION00058000000000000000">
<SPAN CLASS="arabic">4</SPAN>.<SPAN CLASS="arabic">8</SPAN> Output files explained</A>
</H2>

<P>
The primary output of <SPAN  CLASS="textit">get_homologues-est</SPAN> is a set of clusters of sequences in FASTA format.
These are stored in a folder named according to the input data and the choice of parameters.
For instance, a test run with command

<P>
<code>./get_homologues-est.pl -d sample_transcripts_fasta/ -m cluster -M -A -t 0</code>

<P>
will produce an output folder named <code>Esterel_alltaxa_algOMCL_e0_</code>. 
The contents of this folder are summarized in file <code>Esterel_alltaxa_algOMCL_e0_.cluster_list</code>, 
which looks like this:

<P>
<PRE>
cluster 1_TR2804-c0_g1_i1 size=2 taxa=2 file: 1_TR2804-c0_g1_i1.fna aminofile: void
: Esterel.trinity.fna.bz2.nucl
: Franka.trinity.fna.bz2.nucl
cluster 2_TR1554-c0_g1_i1 size=3 taxa=2 file: 2_TR1554-c0_g1_i1.fna aminofile: void
: Esterel.trinity.fna.bz2.nucl
: Esterel.trinity.fna.bz2.nucl
: flcdnas_Hnijo.fna.gz.nucl
cluster 4_TR593-c0_g2_i1 size=2 taxa=1 file: 4_TR593-c0_g2_i1.fna aminofile: void
: Esterel.trinity.fna.bz2.nucl
: Esterel.trinity.fna.bz2.nucl
cluster 6_TR3918-c0_g1_i1 size=2 taxa=2 file: 6_TR3918-c0_g1_i1.fna aminofile: void
: Esterel.trinity.fna.bz2.nucl
: flcdnas_Hnijo.fna.gz.nucl
cluster 7_TR1297-c0_g1_i3 size=4 taxa=2 file: 7_TR1297-c0_g1_i3.fna aminofile: void
: Esterel.trinity.fna.bz2.nucl
: Esterel.trinity.fna.bz2.nucl
: Esterel.trinity.fna.bz2.nucl
: flcdnas_Hnijo.fna.gz.nucl
</PRE>

<P>
This excerpt describes the first resulting clusters, the number of sequences in each (size) and their respective genomes/strains (taxa).
Note that in this case there are only nucleotide clusters; if twin peptides files are provided as input then protein clusters should also be produced.
Each cluster name name is followed by a list of taxa matching the order of sequences contained in it. For instance, if we check the first
cluster (<code>Esterel_0taxa_algOMCL_e0_/1_TR2804-c0_g1_i1.fna</code>), it looks like this:

<P>
<PRE>
&gt;TR2804|c0_g1_i1 [Esterel.trinity.fna.bz2] | aligned:9590-15261 (15270)
ATCTACGTATCCGAAACAATCCCGAGCAAAAGCAGAAAGAAACTTTAAAAAAAATGCGGCAACAGGAG...
&gt;TR3086|c0_g1_i1 [Franka.trinity.fna.bz2] | aligned:1-5672 (5672)
GCATCTTTCACCAAGACTGTGTCAGTCAATGTTTTGGCACCGACATCGCCTGCCAATACAAT...
</PRE>

<P>
Besides clusters, there are other output files that can be produced by <SPAN  CLASS="textit">get_homologues-est</SPAN>;
let's review some of them:

<P>

<UL>
<LI><SPAN  CLASS="textbf">Pan-genome composition matrices</SPAN> (<code>pan_genome_algOMCL.tab, core_genome_algOMCL.tab</code>, see section <A HREF="#clustering">4.2</A>)
contain the results of composition analyses, first described in the 
<A ID="tex2html78"
  HREF="http://eead-csic-compbio.github.io/get_homologues/manual/manual.html#SECTION00058400000000000000">get_homologues</A>
manual.
These tab-separated text files contain estimates of core and pan-genome growth when input genomes are sampled one by one
in random order. There is also a relaxed soft-core version (<code>soft-core_genome_algOMCL.tab</code>) 
which requires a cluster to be supported by 95% of the input strains/genomes in order to be considered.
Let's see the first five lines of <code>core_genome_algOMCL.tab</code>:
<PRE>
g1	g2	g3	g4	
4668	491	85	67	
4668	433	308	67	
4668	2000	344	67	
4668	491	344	67	
20010	1749	290	67
</PRE>

<P>
This example file contains the results of sampling 20 times (see global variable <code>$NOFSAMPLESREPORT</code>) 
4 input sequence sets/transcriptomes. Columns <code>g1</code> to <code>g4</code> indicate the current genome size after adding one genome (from first to fourth).
These files can be used to produce plots with script <SPAN  CLASS="textit">plot_pancore_matrix.pl</SPAN>.
In fact, each row in these files can be plotted as a replicate/snapshot by invoking option <code>-a</code>, as shown in Figure <A HREF="#fig:snapshot">8</A>.

<P>
</LI>
<LI><SPAN  CLASS="textbf">Average Nucleotide Identity matrices</SPAN> (<code>Esterel_alltaxa_algOMCL_e0_Avg_identity.tab</code>, see section <A HREF="#clustering">4.2</A>) 
summarize the average identity among nucleotides sequences clustered together among pairs of genomes/strains (taxa). 
These are tab-separated text files. Note that <code>.fna.*.nucl</code> suffixes have been removed for brevity:
<PRE>
genomes	Esterel.trinity	Franka.trinity	Hs_Turkey-19-24.trinity	flcdnas_Hnijo
Esterel.trinity	100	99.15	98.89	99.30
Franka.trinity	99.15	100	98.79	99.22
Hs_Turkey-19-24.trinity	98.89	98.79	100	99.18
flcdnas_Hnijo	99.30	99.22	99.18	100
</PRE>

<P>
</LI>
<LI><SPAN  CLASS="textbf">Percent Conserved Sequences files</SPAN> (<code>Esterel_0taxa_algOMCL_e0_POCS.tab</code>)
contain the percentage of conserved sequence clusters among pairs of genomes/strains (taxa). 
In other words, POCP/POCS values summarize how many clusters of one genome contain also sequences from another.
These are tab-separated text files. Note that <code>.fna.*.nucl</code> suffixes have been removed for brevity:
<PRE>
genomes	Esterel.trinity	Franka.trinity	Hs_Turkey-19-24.trinity	flcdnas_Hnijo
Esterel.trinity	100	11.15	9.90	17.87
Franka.trinity	11.15	100	9.60	17.55
Hs_Turkey-19-24.trinity	9.90	9.60	100	15.77
flcdnas_Hnijo	17.87	15.55	15.77	100
</PRE>

<P>
</LI>
</UL>

<P>

<H1><A ID="SECTION00060000000000000000"></A> <A ID="protocol"></A>
<BR>
<SPAN CLASS="arabic">5</SPAN> A step-by-step protocol with barley assembled transcripts
</H1>

<P>
This section describes the steps required to proceed with the analysis of barley transcripts
with folder <code>test_barley</code>, which you should get with the software. 
The following commands are to be pasted in your terminal:

<P>
<PRE>
## set get_homologues path if not already in $PATH
export GETHOMS=~/soft/github/get_homologues/

cd test_barley

## 1) prepare sequences
cd seqs

# download all transcriptomes
wget -c -i wgetlist.txt

# extract CDS sequences (this takes several hours)
# choose cdsCPP.sh if dependency Inline::CPP is available in your system
# the script will use 20 CPU cores, please adapt it to your system
./cds.sh 

# clean and compress
#rm -f _* *noORF* *transcript*
#gzip *diamond*

# put cds sequences aside
mv *cds.f*gz ../cds
cd ..

# check lists of accessions are in place (see HOWTO.txt there)
ls cds/*list


## 2) cluster sequences and start the analyses

# calculate protein domain frequencies (Pfam)
$GETHOMS/get_homologues-est.pl -d cds -D -m cluster -o &amp;&gt; log.cds.pfam

# alternatively, if not running in a SGE cluster, taking for instance 20 CPUs 
$GETHOMS/get_homologues-est.pl -d cds -D -n 20 -o &amp;&gt; log.cds.pfam

# calculate 'control' cds clusters
$GETHOMS/get_homologues-est.pl -d cds -M -t 0 -m cluster &amp;&gt; log.cds

# get non-cloud clusters
$GETHOMS/get_homologues-est.pl -d cds -M -t 3 -m cluster &amp;&gt; log.cds.t3

# clusters for dN/dS calculations
$GETHOMS/get_homologues-est.pl -d cds -e -M -t 4 -m cluster &amp;&gt; log.cds.t4.e

# leaf clusters and pangenome growth simulations with soft-core
$GETHOMS/get_homologues-est.pl -d cds -c -z \
  -I cds/leaf.list -M -t 3 -m cluster &amp;&gt; log.cds.leaf.t3.c

# produce pan-genome matrix and allocate clusters to occupancy classes

# all occupancies
$GETHOMS/compare_clusters.pl -d cds_est_homologues/Alexis_0taxa_algOMCL_e0_ \
  -o clusters_cds -m -n &amp;&gt; log.compare_clusters.cds

# excluding cloud clusters, the most unreliable in our benchmarks
$GETHOMS/compare_clusters.pl -d cds_est_homologues/Alexis_3taxa_algOMCL_e0_ \
  -o clusters_cds_t3 -m -n &amp;&gt; log.compare_clusters.cds.t3
$GETHOMS/parse_pangenome_matrix.pl -m clusters_cds_t3/pangenome_matrix_t0.tab -s \
  &amp;&gt; log.parse_pangenome_matrix.cds.t3

# make pan-genome growth plots
$GETHOMS/plot_pancore_matrix.pl -i cds_est_homologues/core_genome_leaf.list_algOMCL.tab \
	-f core_both &amp;&gt; log.core.plots
$GETHOMS/plot_pancore_matrix.pl -i cds_est_homologues/pan_genome_leaf.list_algOMCL.tab \
	-f pan &amp;&gt; log.pan.plots
  

## 3) annotate accessory genes

# find [-t 3] SBCC073 clusters absent from references
$GETHOMS/parse_pangenome_matrix.pl -m clusters_cds_t3/pangenome_matrix_t0.tab \
  -A cds/SBCC073.list -B cds/ref.list -g &amp;&gt; log.acc.SBCC073
mv clusters_cds_t3/pangenome_matrix_t0__pangenes_list.txt \
  clusters_cds_t3/SBCC073_pangenes_list.txt

# how many SBCC073 clusters are there? 
perl -lane 'if($F[0] =~ /SBCC073/){ foreach $c (1 .. $#F){ if($F[$c]&gt;0){ $t++ } }; print $t }' \
  clusters_cds_t3/pangenome_matrix_t0.tab 

# find [-t 3] Scarlett clusters absent from references
$GETHOMS/parse_pangenome_matrix.pl -m clusters_cds_t3/pangenome_matrix_t0.tab \
  -A cds/Scarlett.list -B cds/ref.list -g &amp;&gt; log.acc.Scarlett 
mv clusters_cds_t3/pangenome_matrix_t0__pangenes_list.txt \
  clusters_cds_t3/Scarlett_pangenes_list.txt 

# find [-t 3] H.spontaneum clusters absent from references
$GETHOMS/parse_pangenome_matrix.pl -m clusters_cds_t3/pangenome_matrix_t0.tab \
  -A cds/spontaneum.list -B cds/ref.list -g &amp;&gt; log.acc.spontaneum
mv clusters_cds_t3/pangenome_matrix_t0__pangenes_list.txt \
  clusters_cds_t3/spontaneum_pangenes_list.txt

# Pfam enrichment tests

# core
$GETHOMS/pfam_enrich.pl -d cds_est_homologues -c clusters_cds -n \
	-x clusters_cds_t3/pangenome_matrix_t0__core_list.txt -e -p 1 \
	-r SBCC073 &gt; SBCC073_core.pfam.enrich.tab

$GETHOMS/pfam_enrich.pl -d cds_est_homologues -c clusters_cds -n \
	-x clusters_cds_t3/pangenome_matrix_t0__core_list.txt -e -p 1 \
	-r SBCC073 -t less &gt; SBCC073_core.pfam.deplet.tab

# accessory
$GETHOMS/pfam_enrich.pl -d cds_est_homologues -c clusters_cds -n \
	-x clusters_cds_t3/SBCC073_pangenes_list.txt -e -p 1 -r SBCC073 \
	-f SBCC073_accessory.fna &gt; SBCC073_accessory.pfam.enrich.tab
  
$GETHOMS/pfam_enrich.pl -d cds_est_homologues -c clusters_cds -n \
	-x clusters_cds_t3/Scarlett_pangenes_list.txt -e -p 1 -r Scarlett \
	-f Scarlett_accessory.fna &gt; Scarlett_accessory.pfam.enrich.tab

$GETHOMS/pfam_enrich.pl -d cds_est_homologues -c clusters_cds -n \
	-x clusters_cds_t3/spontaneum_pangenes_list.txt -e -p 1 -r Hs_ \
	-f spontaneum_accessory.fna &gt; spontaneum_accessory.pfam.enrich.tab

# note that output files contain data such as the mean length of sequences

# get merged stats for figure
perl suppl_scripts/_add_Pfam_domains.pl &gt; accessory_stats.tab
perl -lane 'print if($F[0] &gt;= 5 || $F[1] &gt;= 5 || $F[2] &gt;= 5)' \
  accessory_stats.tab  &gt; accessory_stats_min5.tab
Rscript suppl_scripts/_plot_heatmap.R
</PRE>

<P>

<H1><A ID="SECTION00070000000000000000"></A> <A ID="FAQs"></A>
<BR>
<SPAN CLASS="arabic">6</SPAN> Frequently asked questions (FAQs)
</H1>

<P>
Please see also <A ID="tex2html82"
  HREF="https://github.com/eead-csic-compbio/get_homologues/issues">a</A>nd FAQs in
<A ID="tex2html83"
  HREF="https://github.com/eead-csic-compbio/get_homologues/blob/master/manual_get_homologues.pdf">manual_get_homologues.pdf</A>. 
Most apply also to <SPAN  CLASS="textit">get_homologues-est.pl</SPAN>, such as running on a computer farm or on Windows systems.

<P>

<UL>
<LI>What's the performance gain of v2?

<P>
After evolving parts of the original code base, and fixing some bugs (see CHANGES.txt), both 
<SPAN  CLASS="textit">get_homologues.pl</SPAN> and <SPAN  CLASS="textit">get_homologues-est.pl</SPAN> have significantly improved their performance, as can be seen 
in the figure, which combines data from the original benchmark and new data generated after v2 was in place. 

<P>

<DIV class="CENTER"><A ID="fig:RAMtimev2"></A><A ID="545"></A>
<TABLE>
<CAPTION class="BOTTOM"><STRONG>Figure 11:</STRONG>
Computing time and RAM requirements of the original algorithm (OMCL, measured on 6 sequence sets) 
as compared to the updated v2 code (measured on 3 three sets).</CAPTION>
<TR><TD>
<DIV class="CENTER">
<IMG STYLE=""
 SRC="./performance_v2.png"
 ALT="Image performance_v2">

</DIV></TD></TR>
</TABLE>
</DIV>

<P>
</LI>
<LI>What are the main caveats when clustering transcripts/CDS sequences?

<P>
<SPAN  CLASS="textit">get_homologues-est.pl</SPAN> has been mainly tested with plant sequences, using both CDS sets from whole-genome annotations and also 
transcripts from expression experiments. The main problems we have found so far are split genes, frequent artifacts in genome assemblies,
incomplete genes which lack exons, for the same previous reasons, and retained introns, which are common among plant transcripts.
These three common situations are illustrated in the figure. 

<P>

<DIV class="CENTER"><A ID="fig:ESTcaveats"></A><A ID="554"></A>
<TABLE>
<CAPTION class="BOTTOM"><STRONG>Figure 12:</STRONG>
Common problems faced when clustering transcripts/CDS sequences.</CAPTION>
<TR><TD>
<DIV class="CENTER">
<IMG STYLE=""
 SRC="./get_homs-est_cdhit.png"
 ALT="Image get_homs-est_cdhit">

</DIV></TD></TR>
</TABLE>
</DIV>

<P>
</LI>
<LI>What are those chimeras warnings produced when running <SPAN  CLASS="textit">transcripts2cds</SPAN>?

<P>
When subroutine transcripts::parse_blastx_cds_sequences reads BLASTX/DIAMOND results checks whether secondary alignments 
to the same protein sequence are in the same strand as the primary alignment. In cases were a second or third BLAST HSP of the same 
hit is found on the opposite strand, that warning is printed to alert the user.

<P>
</LI>
<LI>Why have you not implemented the COG algorithm in the <SPAN  CLASS="textit">get_homologues-est.pl</SPAN>?

<P>
We have left the COG algorithm out of <SPAN  CLASS="textit">get_homologues-est.pl</SPAN> as it will take some more work to integrate it
with redundant isoform calling, which is important for EST datasets. However, it should be possible
to do it.

<P>
</LI>
<LI>The number of clusters produced with <code>-C 75 -S 85</code> does not match the pangenome/pantranscriptome size estimated with option <code>-c</code>

<P>
The reason for these discrepancies is that these are fundamentally different analyses. 
While the default runmode simply groups sequences trying to put in the same cluster isoforms of orthologues and very close inparalogues, 
a genome composition analysis performs a simulation in order to estimate how many novel sequences are added by 
genomes/transcriptomes sampled in random order. In terms of code, there are a couple of key global variables set in
<code>lib/marfil_homology.pm</code>, lines 135-138, which control how a gene/transcript is compared to previously processed sequences 
in order to call it novel:
<PRE>
$MIN_PERSEQID_HOM_EST = 70.0;      
$MIN_COVERAGE_HOM_EST = 50.0;
</PRE>

<P>
These values are equivalent to say that any sequence with <!-- MATH
 $coverage \ge 50\%$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="111" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img10.png"
 ALT="$ coverage \ge 50\%$"></SPAN> 
and <!-- MATH
 $identity \ge 70\%$
 -->
<SPAN CLASS="MATH"><IMG
 WIDTH="103" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img11.png"
 ALT="$ identity \ge 70\%$"></SPAN> to previous genes/transcripts 
will be considered simply a homologue and won't be accumulated to the growing pangenome/pantranscriptome. 
You might want to change these values to increase or relax the stringency and to match the parameters set to produce your clusters.

<P>
</LI>
<LI>Can <SPAN  CLASS="textit">get_homologues-est.pl</SPAN> be used to analyze non-coding sequences?

<P>
In principle the software should work with any type of nucleotide sequences. For instance, the next figure shows how it can used
to analyze conserved non-coding sequences among <SPAN  CLASS="textit">Brachypodium distachyon</SPAN> and rice, with a median BLASTN alignment length of 32.

<P>

<DIV class="CENTER"><A ID="fig:CNS"></A><A ID="569"></A>
<TABLE>
<CAPTION class="BOTTOM"><STRONG>Figure 13:</STRONG>
Core-genome composition analysis of conserved non-coding sequences (CNS) from 56 Brachypodium distachyon ecotypes and rice.</CAPTION>
<TR><TD>
<DIV class="CENTER">
<IMG STYLE=""
 SRC="./brachy_rice_CNS.jpg"
 ALT="Image brachy_rice_CNS">

</DIV></TD></TR>
</TABLE>
</DIV>

<P>
</LI>
<LI>I produced 2 different parsimony trees with <SPAN  CLASS="textit">compare_clusters.pl</SPAN>, is there a way to merge them and add bootstrap values?

<P>
The two trees are equally parsimonious, that is, have the same parsimony score but different topologies. 
One possibility to combine them into one topology is to compute either the majority rule consensus (mjr) tree, 
for example with consense from the PHYLIP package, or represent a network consensus with a program such as splitstree.

<P>
Regarding the bootstrapping, you could write some R code (or in any other language) to randomly sample the columns 
in the pangenome matrix with replacement to construct a new, bootstrapped matrix with the same number of columns 
as the original one. You should generate 100 or 500 of these matrices and then run <code>pars</code> on each one of them. 
Then run consense to obtain the mjr consensus tree and associated split frequencies (bootstrap support values for each bipartition).
An easy way of achieving this would be with R's <A ID="tex2html84"
  HREF="https://cran.r-project.org/web/packages/boot/boot.pdf">boot</A>
package 
(see <A ID="tex2html85"
  HREF="http://www.statmethods.net/advstats/bootstrapping.html">example</A>).

<P>
Another option is to call seqboot from the PHYLIP package to generate N bootstrap pseudo-replicates of the matrix. 
Rename the resulting file as <code>infile</code> and call <code>pars</code> to read the file, using the option <code>m no_of_pseudoreplicates</code>
to run the standard (Fitch) parsimony analysis on each of the bootstraped matrices. PHYLIP <code>pars</code> will generate an outtree file 
containing as many trees as bootstraped matrices found in infile. Rename outtree to intree and call <code>consense</code> to generate the 
default majority rule consensus tree. This tree is only a cladogram (only topology, no branch lengths). 
The node labels correspond to the number of bootstrap pseudoreplicates in which that particular bipartition was found. 

<P>
</LI>
<LI>How can I produce a maximum likelihood (ML) tree with bootstrap values from a pangenome matrix?

<P>
We recommend script <code>estimate_pangenome_trees.sh</code> from the <A ID="tex2html86"
  HREF="https://github.com/vinuesa/get_phylomarkers">GET_PHYLOMARKERS</A>
pipeline. 

<P>
Another alternative is to use the <code>.fasta</code> version of the pangenome matrix produced by script <code>./compare_clusters.pl -m </code> ,
next to the <code>.tab</code> and <code>.phy</code> files. 
This FASTA file can be analyzed with ML software such as <A ID="tex2html87"
  HREF="http://iqtree.cibiv.univie.ac.at">IQ-TREE</A>
(PubMed=<A ID="tex2html88"
  HREF="https://www.ncbi.nlm.nih.gov/pubmed/25371430">25371430</A>) both online or in the terminal with a command such as:
<BR><code>path_to_iqtree -s pangenome_matrix_t0.fasta -st BIN -m TEST -bb 1000 -alrt 1000</code>
<BR>
This will produce an optimal ML tree after selecting a binary substitution model with both bootstrap and aLRT support values.

<P>
</LI>
<LI>Is there a way to plot ANI matrices of soft-core clusters?

<P>
Let's say you have 20 genomes, then 95% of them are exaclty 19 taxa, which is the minimum occupancy that defines soft-core clusters
(see global variable <code>$SOFTCOREFRACTION</code>). You should then compute the ANI matrix as follows:

<P>
<code>./get_homologues.pl -d your_data -a 'CDS' -A -M -t 19</code>

<P>
And then plot the resulting matrix with script <SPAN  CLASS="textit">hcluster_pangenome_matrix.sh</SPAN>.

<P>
</LI>
<LI>When I use the hcluster_pangenome_matrix.sh script the trees in the output of the newick file and the heatmap differ. Is there a reason for this?

<P>
The difference in the topologies of the NJ trees and the row-dendrogram of the heatmaps differ because the heatmaps 
are ordered bi-dimensionally. That is, the heatmap plot shows only the row-dendrogram, but the matrix is ordered also by columns.
The NJ tree is computed from the distance matrix that you indicate the program to calculate for you (ward.D2 is the default). 

<P>
</LI>
<LI>I ran <SPAN  CLASS="textit">get_homologues</SPAN> with fasta files of 78 genomes; is there a way to export a 78 x 78 matrix 
of the number of homologues shared between each genome?

<P>
If you did your analysis requesting cluster of all occupancies (<code>-t 0</code>) then you can get what you want in two steps. 
First, you must produce a pangenome matrix with <code>compare_clusters -d ... -m</code>. Now it is possible to request an intersection 
pangenome matrix (<code>pangenome_matrix_t0__intersection.tab</code>) which contains the number of sequence clusters shared by 
any two pairs of genomes with <code>parse_pangenome_matrix.pl -m pangenome_matrix_t0.tab -s -x</code>.
Note that these clusters might contain several inparalogues of the same species.

<P>
</LI>
<LI>How can I use <SPAN  CLASS="textit">get_homologues</SPAN> to produce clusters for GET_PHYLOMARKERS?

<P>
You should use option <code>-e</code> and make sure that your input FASTA nucleotide files have twin files with matching peptide sequences.
Then, in GET_PHYLOMARKERS make sure to set option -f EST.

<P>
</LI>
<LI>I have been using GET_HOMOLOGUES and I could not figure out which is the default value for saving blastn hits, I mean,
the value set for '-max_target_seqs'

<P>
BLAST parameter <code>-max_target_seqs</code> is set to the number of sequences of the query proteome, which usually is a large number
that ensures all good quality hits are recovered. Read more <A ID="tex2html89"
  HREF="https://github.com/eead-csic-compbio/get_homologues/issues/38">here</A>.

<P>
</LI>
<LI>Why does <SPAN  CLASS="textit">get_homologues</SPAN> not normalize alignment scores as OrthoFinder?

<P>
It is possible to experimentally normalize the scores using the script 
<A ID="tex2html90"
  HREF="https://github.com/eead-csic-compbio/get_homologues/tree/master/user_utils/normalize">here</A>.
However, our tests suggest this might cause unexpected consequences and for that reason this is not done by default.

<P>
</LI>
</UL>

<P>

<P>

<H1><A ID="SECTION00080000000000000000">
<SPAN CLASS="arabic">7</SPAN> Credits and references</A>
</H1>

<P>
<SPAN  CLASS="textit">get_homologues-est.pl</SPAN> is designed, created and maintained at the 
<A ID="tex2html91"
  HREF="http://www.eead.csic.es/compbio">Laboratory of Computational Biology</A>
at 
Estación Experimental de Aula Dei-CSIC in Zaragoza (Spain) and at the 
<A ID="tex2html92"
  HREF="http://www.ccg.unam.mx/~vinuesa">Center for Genomic Sciences</A>
of 
Universidad Nacional Autónoma de México (CCG/UNAM).

<P>
The code was written mostly by Bruno Contreras-Moreira and Pablo Vinuesa, but it also includes 
code and binaries from <A ID="tex2html93"
  HREF="http://www.orthomcl.org">OrthoMCL v1.4</A>
(algorithm OMCL, <code>-M</code>),
<A ID="tex2html94"
  HREF="http://blast.ncbi.nlm.nih.gov">NCBI Blast+</A>, <A ID="tex2html95"
  HREF="https://github.com/desmid/mview">MVIEW</A>,
<A ID="tex2html96"
  HREF="https://github.com/bbuchfink/diamond">DIAMOND</A>
and <A ID="tex2html97"
  HREF="http://www.bioperl.org">BioPerl 1.5.2</A>.

<P>
Other contributors: Carlos P Cantalapiedra, Alvaro Rodriguez del Rio, Ruben Sancho, Roland Wilhelm, 
David A Wilkinson.

<BR>
<BR>
We ask the reader to cite the main reference describing the <SPAN  CLASS="textit">get_homologues</SPAN> software,

<P>

<UL>
<LI>Contreras-Moreira B, Cantalapiedra CP, Garcia Pereira MJ, Gordon S, Vogel JP,
Igartua E, Casas AM and Vinuesa P (2017) Analysis of plant pan-genomes and
transcriptomes with GET_HOMOLOGUES-EST, a clustering solution for sequences of
the same species. Front. Plant Sci. https://doi.org/10.3389/fpls.2017.00184
</LI>
<LI>Contreras-Moreira B, Rodriguez del Rio A, Cantalapiedra CP, Sancho R, Vinuesa P 
(2022) Pangenome Analysis of Plant Transcripts and Coding Sequences. In: Pereira-Santana A, 
Gamboa-Tuz SD, Rodriguez-Zapata LC (eds) Plant Comparative Genomics. Methods 
in Molecular Biology, vol 2512. Humana, New York, NY. 
https://doi.org/10.1007/978-1-0716-2429-6_9
</LI>
</UL>

<P>
and also the original papers describing the included algorithms and databases, accordingly:

<P>

<UL>
<LI>Li L, Stoeckert CJ Jr, Roos DS (2003) OrthoMCL: identification of ortholog 
groups for eukaryotic genomes. Genome Res. 13(9):2178-89.

<P>
</LI>
<LI>Altschul SF, Madden TL, Schaffer AA, Zhang J, Zhang Z, Miller W and Lipman DJ (1997)
Gapped BLAST and PSI-BLAST: a new generation of protein database search programs.
Nucl. Acids Res. 25(17): 3389-3402.

<P>
</LI>
<LI>Stajich JE, Block D, Boulez K, Brenner SE, Chervitz SA, Dagdigian C, Fuellen G, 
Gilbert JG, Korf I, Lapp H, Lehvslaiho H, Matsalla C, Mungall CJ, Osborne BI, 
Pocock MR, Schattner P, Senger M, Stein LD, Stupka E, Wilkinson MD, Birney E. (2002)
The Bioperl toolkit: Perl modules for the life sciences. Genome Res. 12(10):1611-8.

<P>
</LI>
<LI>hmmscan :: search sequence(s) against a profile database HMMER 3.1b2 (Feb 2015) http://hmmer.org
Copyright (C) 2015 Howard Hughes Medical Institute.
Freely distributed under the GNU General Public License (GPLv3).

<P>
</LI>
<LI>Paysan-Lafosse, Typhaine et al. (2025) The Pfam protein families database:
embracing AI/ML. Nucleic Acids Res. 53(D1): D523-D534.

<P>
</LI>
<LI>Haas BJ, Papanicolaou A, Yassour M et al. (2013) De novo transcript sequence 
reconstruction from RNA-seq using the Trinity platform for reference generation 
and analysis. Nat Protoc. 8(8):1494-512.

<P>
</LI>
<LI>Brown NP, Leroy C, Sander C (1998) MView: A Web compatible database search or 
multiple alignment viewer. Bioinformatics. 14 (4):380-381. 

<P>
</LI>
<LI>Buchfink B, Xie C, Huson DH (2015) Fast and sensitive protein alignment using 
DIAMOND. Nat Methods. 12(1):59-60

<P>
</LI>
</UL>

<P>
If you use the accompanying scripts the following references should also be cited:

<UL>
<LI>R Core Team (2013) R: A Language and Environment for Statistical Computing. http://www.R-project.org
R Foundation for Statistical Computing, Vienna, Austria, ISBN3-900051-07-0 

<P>
</LI>
</UL>

<P>

<H1><A ID="SECTION00090000000000000000">
About this document ...</A>
</H1>
 <STRONG>get_homologues-est manual</STRONG><P>
This document was generated using the
<A HREF="http://www.latex2html.org/">LaTeX2HTML</A> translator Version 2019.2 (Released June 5, 2019)
<P>
The command line arguments were: <BR>
 <kbd>latex2html manual-est -no_antialias_text -split 0 -dir manual-est -no_navigation -show_section_numbers</kbd>
<P>
The translation was initiated on 2026-01-08
<BR><HR>

</BODY>
</HTML>
